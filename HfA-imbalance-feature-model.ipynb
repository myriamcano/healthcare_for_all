{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab: Handling Data Imbalance in Classification Models\n",
    "\n",
    "## Overview\n",
    "\n",
    "The objective of this task is to address data imbalance in classification models using the 'Healthcare For All' dataset. The dataset, named `learningSet.csv`, is utilized to predict the likelihood of donation (TargetB) and the donation amount (TargetD).\n",
    "\n",
    "## Context\n",
    "\n",
    "This task revolves around the Healthcare for All Case Study, leveraging historical donor data to construct a machine learning model. The aim is to identify potential donors and forecast their donation amounts.\n",
    "\n",
    "## Tasks Undertaken\n",
    "\n",
    "### Initial Data Assessment and Preprocessing\n",
    "\n",
    "1. Imported necessary libraries.\n",
    "2. Loaded the dataset into Python as the `donors` dataframe.\n",
    "3. Inspected column datatypes.\n",
    "4. Segregated data into numerical and categorical subsets.\n",
    "5. Handled null values and performed data preprocessing.\n",
    "\n",
    "### Modeling Phase\n",
    "\n",
    "1. Conducted a comprehensive examination of numerical and categorical column datatypes, making adjustments as required.\n",
    "2. Reassembled the numerical and categorical data into the X dataframe, designating TargetB as y.\n",
    "3. Split the data into training and testing sets, further partitioning them into numerical and categorical subsets.\n",
    "4. Applied feature scaling using either MinMax Scaler or Standard Scaler to train_num and test_num.\n",
    "5. Employed One-Hot Encoding or Ordinal Encoding to encode categorical features in train_cat and test_cat.\n",
    "6. Fitted a logistic regression model on the training data and evaluated its accuracy on the test data.\n",
    "\n",
    "### Handling Data Imbalance\n",
    "\n",
    "1. Evaluated the extent of class imbalance.\n",
    "2. Utilized resampling strategies such as upsampling and downsampling to create a balanced representation of both classes.\n",
    "3. After each resampling iteration, assessed the model's accuracy to gauge its performance improvement.\n",
    "\n",
    "### Feature Selection\n",
    "\n",
    "Additionally, feature selection was conducted to identify and retain the most relevant features for modeling. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data\n",
    "numerical = pd.read_csv('C:/Ironhack/Week7/7.1, 7.2 Feature Selection (Review)/lab-revisiting-machine-learning/numerical7_02.csv')\n",
    "categorical = pd.read_csv('C:/Ironhack/Week7/7.1, 7.2 Feature Selection (Review)/lab-revisiting-machine-learning/categorical7_02.csv')\n",
    "target = pd.read_csv('C:/Ironhack/Week7/7.1, 7.2 Feature Selection (Review)/lab-revisiting-machine-learning/target7_02.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>TARGET_B</th>\n",
       "      <th>TARGET_D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95407</th>\n",
       "      <td>95407</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95408</th>\n",
       "      <td>95408</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95409</th>\n",
       "      <td>95409</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95410</th>\n",
       "      <td>95410</td>\n",
       "      <td>1</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95411</th>\n",
       "      <td>95411</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>95412 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0  TARGET_B  TARGET_D\n",
       "0               0         0       0.0\n",
       "1               1         0       0.0\n",
       "2               2         0       0.0\n",
       "3               3         0       0.0\n",
       "4               4         0       0.0\n",
       "...           ...       ...       ...\n",
       "95407       95407         0       0.0\n",
       "95408       95408         0       0.0\n",
       "95409       95409         0       0.0\n",
       "95410       95410         1      18.0\n",
       "95411       95411         0       0.0\n",
       "\n",
       "[95412 rows x 3 columns]"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0      int64\n",
       "ODATEDW         int64\n",
       "TCODE           int64\n",
       "DOB             int64\n",
       "AGE           float64\n",
       "               ...   \n",
       "AVGGIFT       float64\n",
       "CONTROLN        int64\n",
       "HPHONE_D        int64\n",
       "RFA_2F          int64\n",
       "CLUSTER2      float64\n",
       "Length: 332, dtype: object"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking data types\n",
    "numerical.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>ODATEDW</th>\n",
       "      <th>TCODE</th>\n",
       "      <th>DOB</th>\n",
       "      <th>AGE</th>\n",
       "      <th>NUMCHLD</th>\n",
       "      <th>INCOME</th>\n",
       "      <th>WEALTH1</th>\n",
       "      <th>HIT</th>\n",
       "      <th>MBCRAFT</th>\n",
       "      <th>...</th>\n",
       "      <th>CARDGIFT</th>\n",
       "      <th>LASTGIFT</th>\n",
       "      <th>LASTDATE</th>\n",
       "      <th>FISTDATE</th>\n",
       "      <th>TIMELAG</th>\n",
       "      <th>AVGGIFT</th>\n",
       "      <th>CONTROLN</th>\n",
       "      <th>HPHONE_D</th>\n",
       "      <th>RFA_2F</th>\n",
       "      <th>CLUSTER2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>8901</td>\n",
       "      <td>0</td>\n",
       "      <td>3712</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>14</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9512</td>\n",
       "      <td>8911</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.741935</td>\n",
       "      <td>95515</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>39.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>9401</td>\n",
       "      <td>1</td>\n",
       "      <td>5202</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>25.0</td>\n",
       "      <td>9512</td>\n",
       "      <td>9310</td>\n",
       "      <td>18.0</td>\n",
       "      <td>15.666667</td>\n",
       "      <td>148535</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>9001</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>61.611649</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>14</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9512</td>\n",
       "      <td>9001</td>\n",
       "      <td>12.0</td>\n",
       "      <td>7.481481</td>\n",
       "      <td>15078</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>60.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>8701</td>\n",
       "      <td>0</td>\n",
       "      <td>2801</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9512</td>\n",
       "      <td>8702</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6.812500</td>\n",
       "      <td>172556</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>41.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>8601</td>\n",
       "      <td>0</td>\n",
       "      <td>2001</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>60</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>15.0</td>\n",
       "      <td>9601</td>\n",
       "      <td>7903</td>\n",
       "      <td>14.0</td>\n",
       "      <td>6.864865</td>\n",
       "      <td>7112</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95407</th>\n",
       "      <td>95407</td>\n",
       "      <td>9601</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>61.611649</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>9602</td>\n",
       "      <td>9602</td>\n",
       "      <td>9.0</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>184568</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95408</th>\n",
       "      <td>95408</td>\n",
       "      <td>9601</td>\n",
       "      <td>1</td>\n",
       "      <td>5001</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>9603</td>\n",
       "      <td>9603</td>\n",
       "      <td>9.0</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>122706</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95409</th>\n",
       "      <td>95409</td>\n",
       "      <td>9501</td>\n",
       "      <td>1</td>\n",
       "      <td>3801</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9610</td>\n",
       "      <td>9410</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.285714</td>\n",
       "      <td>189641</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>34.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95410</th>\n",
       "      <td>95410</td>\n",
       "      <td>8601</td>\n",
       "      <td>0</td>\n",
       "      <td>4005</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>18</td>\n",
       "      <td>18.0</td>\n",
       "      <td>9701</td>\n",
       "      <td>8612</td>\n",
       "      <td>4.0</td>\n",
       "      <td>12.146341</td>\n",
       "      <td>4693</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95411</th>\n",
       "      <td>95411</td>\n",
       "      <td>8801</td>\n",
       "      <td>2</td>\n",
       "      <td>1801</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>11</td>\n",
       "      <td>100.0</td>\n",
       "      <td>9612</td>\n",
       "      <td>8803</td>\n",
       "      <td>6.0</td>\n",
       "      <td>96.794872</td>\n",
       "      <td>185114</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>95412 rows × 332 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0  ODATEDW  TCODE   DOB        AGE  NUMCHLD  INCOME  WEALTH1  \\\n",
       "0               0     8901      0  3712  60.000000      0.0     5.0      5.0   \n",
       "1               1     9401      1  5202  46.000000      1.0     6.0      9.0   \n",
       "2               2     9001      1     0  61.611649      0.0     3.0      1.0   \n",
       "3               3     8701      0  2801  70.000000      0.0     1.0      4.0   \n",
       "4               4     8601      0  2001  78.000000      1.0     3.0      2.0   \n",
       "...           ...      ...    ...   ...        ...      ...     ...      ...   \n",
       "95407       95407     9601      1     0  61.611649      0.0     5.0      5.0   \n",
       "95408       95408     9601      1  5001  48.000000      1.0     7.0      9.0   \n",
       "95409       95409     9501      1  3801  60.000000      0.0     5.0      5.0   \n",
       "95410       95410     8601      0  4005  58.000000      0.0     7.0      5.0   \n",
       "95411       95411     8801      2  1801  80.000000      0.0     5.0      8.0   \n",
       "\n",
       "       HIT  MBCRAFT  ...  CARDGIFT  LASTGIFT  LASTDATE  FISTDATE  TIMELAG  \\\n",
       "0        0      0.0  ...        14      10.0      9512      8911      4.0   \n",
       "1       16      0.0  ...         1      25.0      9512      9310     18.0   \n",
       "2        2      0.0  ...        14       5.0      9512      9001     12.0   \n",
       "3        2      0.0  ...         7      10.0      9512      8702      9.0   \n",
       "4       60      1.0  ...         8      15.0      9601      7903     14.0   \n",
       "...    ...      ...  ...       ...       ...       ...       ...      ...   \n",
       "95407    0      0.0  ...         0      25.0      9602      9602      9.0   \n",
       "95408    1      0.0  ...         0      20.0      9603      9603      9.0   \n",
       "95409    0      0.0  ...         4      10.0      9610      9410      3.0   \n",
       "95410    0      0.0  ...        18      18.0      9701      8612      4.0   \n",
       "95411    3      0.0  ...        11     100.0      9612      8803      6.0   \n",
       "\n",
       "         AVGGIFT  CONTROLN  HPHONE_D  RFA_2F  CLUSTER2  \n",
       "0       7.741935     95515         0       4      39.0  \n",
       "1      15.666667    148535         0       2       1.0  \n",
       "2       7.481481     15078         1       4      60.0  \n",
       "3       6.812500    172556         1       4      41.0  \n",
       "4       6.864865      7112         1       2      26.0  \n",
       "...          ...       ...       ...     ...       ...  \n",
       "95407  25.000000    184568         0       1      12.0  \n",
       "95408  20.000000    122706         1       1       2.0  \n",
       "95409   8.285714    189641         1       3      34.0  \n",
       "95410  12.146341      4693         1       4      11.0  \n",
       "95411  96.794872    185114         1       1      12.0  \n",
       "\n",
       "[95412 rows x 332 columns]"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking columns\n",
    "numerical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0     int64\n",
       "STATE         object\n",
       "CLUSTER        int64\n",
       "HOMEOWNR      object\n",
       "GENDER        object\n",
       "DATASRCE       int64\n",
       "SOLIH          int64\n",
       "VETERANS      object\n",
       "RFA_2R        object\n",
       "RFA_2A        object\n",
       "GEOCODE2      object\n",
       "DOMAIN_A      object\n",
       "DOMAIN_B       int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking data types\n",
    "categorical.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>STATE</th>\n",
       "      <th>CLUSTER</th>\n",
       "      <th>HOMEOWNR</th>\n",
       "      <th>GENDER</th>\n",
       "      <th>DATASRCE</th>\n",
       "      <th>SOLIH</th>\n",
       "      <th>VETERANS</th>\n",
       "      <th>RFA_2R</th>\n",
       "      <th>RFA_2A</th>\n",
       "      <th>GEOCODE2</th>\n",
       "      <th>DOMAIN_A</th>\n",
       "      <th>DOMAIN_B</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>IL</td>\n",
       "      <td>36</td>\n",
       "      <td>N</td>\n",
       "      <td>F</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>L</td>\n",
       "      <td>E</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>CA</td>\n",
       "      <td>14</td>\n",
       "      <td>H</td>\n",
       "      <td>M</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>L</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>NC</td>\n",
       "      <td>43</td>\n",
       "      <td>U</td>\n",
       "      <td>M</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>L</td>\n",
       "      <td>E</td>\n",
       "      <td>C</td>\n",
       "      <td>R</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>CA</td>\n",
       "      <td>44</td>\n",
       "      <td>U</td>\n",
       "      <td>F</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>L</td>\n",
       "      <td>E</td>\n",
       "      <td>C</td>\n",
       "      <td>R</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>FL</td>\n",
       "      <td>16</td>\n",
       "      <td>H</td>\n",
       "      <td>F</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>N</td>\n",
       "      <td>L</td>\n",
       "      <td>F</td>\n",
       "      <td>A</td>\n",
       "      <td>S</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95407</th>\n",
       "      <td>95407</td>\n",
       "      <td>other</td>\n",
       "      <td>27</td>\n",
       "      <td>N</td>\n",
       "      <td>M</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>L</td>\n",
       "      <td>G</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95408</th>\n",
       "      <td>95408</td>\n",
       "      <td>TX</td>\n",
       "      <td>24</td>\n",
       "      <td>H</td>\n",
       "      <td>M</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>L</td>\n",
       "      <td>F</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95409</th>\n",
       "      <td>95409</td>\n",
       "      <td>MI</td>\n",
       "      <td>30</td>\n",
       "      <td>N</td>\n",
       "      <td>M</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>L</td>\n",
       "      <td>E</td>\n",
       "      <td>B</td>\n",
       "      <td>C</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95410</th>\n",
       "      <td>95410</td>\n",
       "      <td>CA</td>\n",
       "      <td>24</td>\n",
       "      <td>H</td>\n",
       "      <td>F</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>N</td>\n",
       "      <td>L</td>\n",
       "      <td>F</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95411</th>\n",
       "      <td>95411</td>\n",
       "      <td>NC</td>\n",
       "      <td>24</td>\n",
       "      <td>U</td>\n",
       "      <td>F</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>N</td>\n",
       "      <td>L</td>\n",
       "      <td>G</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>95412 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0  STATE  CLUSTER HOMEOWNR GENDER  DATASRCE  SOLIH VETERANS  \\\n",
       "0               0     IL       36        N      F         0      0        N   \n",
       "1               1     CA       14        H      M         3      0        N   \n",
       "2               2     NC       43        U      M         3      0        N   \n",
       "3               3     CA       44        U      F         3      0        N   \n",
       "4               4     FL       16        H      F         3     12        N   \n",
       "...           ...    ...      ...      ...    ...       ...    ...      ...   \n",
       "95407       95407  other       27        N      M         0      0        N   \n",
       "95408       95408     TX       24        H      M         3      0        N   \n",
       "95409       95409     MI       30        N      M         0      0        N   \n",
       "95410       95410     CA       24        H      F         2     12        N   \n",
       "95411       95411     NC       24        U      F         3     12        N   \n",
       "\n",
       "      RFA_2R RFA_2A GEOCODE2 DOMAIN_A  DOMAIN_B  \n",
       "0          L      E        C        T         2  \n",
       "1          L      G        A        S         1  \n",
       "2          L      E        C        R         2  \n",
       "3          L      E        C        R         2  \n",
       "4          L      F        A        S         2  \n",
       "...      ...    ...      ...      ...       ...  \n",
       "95407      L      G        C        C         2  \n",
       "95408      L      F        A        C         1  \n",
       "95409      L      E        B        C         3  \n",
       "95410      L      F        A        C         1  \n",
       "95411      L      G        C        C         1  \n",
       "\n",
       "[95412 rows x 13 columns]"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop solih and veterans columns \n",
    "categorical = categorical.drop(columns= ['SOLIH','VETERANS','Unnamed: 0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop unnamed column\n",
    "numerical = numerical.drop(columns=['Unnamed: 0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    43549\n",
       "2    23455\n",
       "0    21280\n",
       "1     7128\n",
       "Name: DATASRCE, dtype: int64"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DATASRCE column values distribution\n",
    "categorical['DATASRCE'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "#classifying numerical values between continuous and discrete variables\n",
    "\n",
    "#The method takes in numerical values only and loops through each column\n",
    "#The decision taken is the if the number of unique values < 2% of the total values, then they are discrete\n",
    "#Else it's continuous.\n",
    "\n",
    "def diff_variable(x):\n",
    "    continuous_df = pd.DataFrame()\n",
    "    discrete_df = pd.DataFrame()\n",
    "    \n",
    "    for column in x.columns:\n",
    "        length = len(x[column])\n",
    "        uni_length = len(x[column].unique())\n",
    "        #print (uni_length/length)\n",
    "        \n",
    "        if (uni_length/length)*100 <= 2:\n",
    "            discrete_df[column] = x[column]\n",
    "        else:\n",
    "            continuous_df[column] = x[column]\n",
    "    \n",
    "    return continuous_df, discrete_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\usuario\\AppData\\Local\\Temp\\ipykernel_10332\\2686454219.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  discrete_df[column] = x[column]\n",
      "C:\\Users\\usuario\\AppData\\Local\\Temp\\ipykernel_10332\\2686454219.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  discrete_df[column] = x[column]\n",
      "C:\\Users\\usuario\\AppData\\Local\\Temp\\ipykernel_10332\\2686454219.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  discrete_df[column] = x[column]\n",
      "C:\\Users\\usuario\\AppData\\Local\\Temp\\ipykernel_10332\\2686454219.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  discrete_df[column] = x[column]\n",
      "C:\\Users\\usuario\\AppData\\Local\\Temp\\ipykernel_10332\\2686454219.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  discrete_df[column] = x[column]\n",
      "C:\\Users\\usuario\\AppData\\Local\\Temp\\ipykernel_10332\\2686454219.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  discrete_df[column] = x[column]\n",
      "C:\\Users\\usuario\\AppData\\Local\\Temp\\ipykernel_10332\\2686454219.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  discrete_df[column] = x[column]\n",
      "C:\\Users\\usuario\\AppData\\Local\\Temp\\ipykernel_10332\\2686454219.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  discrete_df[column] = x[column]\n",
      "C:\\Users\\usuario\\AppData\\Local\\Temp\\ipykernel_10332\\2686454219.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  discrete_df[column] = x[column]\n",
      "C:\\Users\\usuario\\AppData\\Local\\Temp\\ipykernel_10332\\2686454219.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  discrete_df[column] = x[column]\n",
      "C:\\Users\\usuario\\AppData\\Local\\Temp\\ipykernel_10332\\2686454219.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  discrete_df[column] = x[column]\n",
      "C:\\Users\\usuario\\AppData\\Local\\Temp\\ipykernel_10332\\2686454219.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  discrete_df[column] = x[column]\n",
      "C:\\Users\\usuario\\AppData\\Local\\Temp\\ipykernel_10332\\2686454219.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  discrete_df[column] = x[column]\n",
      "C:\\Users\\usuario\\AppData\\Local\\Temp\\ipykernel_10332\\2686454219.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  discrete_df[column] = x[column]\n",
      "C:\\Users\\usuario\\AppData\\Local\\Temp\\ipykernel_10332\\2686454219.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  discrete_df[column] = x[column]\n",
      "C:\\Users\\usuario\\AppData\\Local\\Temp\\ipykernel_10332\\2686454219.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  discrete_df[column] = x[column]\n",
      "C:\\Users\\usuario\\AppData\\Local\\Temp\\ipykernel_10332\\2686454219.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  discrete_df[column] = x[column]\n",
      "C:\\Users\\usuario\\AppData\\Local\\Temp\\ipykernel_10332\\2686454219.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  discrete_df[column] = x[column]\n",
      "C:\\Users\\usuario\\AppData\\Local\\Temp\\ipykernel_10332\\2686454219.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  discrete_df[column] = x[column]\n",
      "C:\\Users\\usuario\\AppData\\Local\\Temp\\ipykernel_10332\\2686454219.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  discrete_df[column] = x[column]\n",
      "C:\\Users\\usuario\\AppData\\Local\\Temp\\ipykernel_10332\\2686454219.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  discrete_df[column] = x[column]\n",
      "C:\\Users\\usuario\\AppData\\Local\\Temp\\ipykernel_10332\\2686454219.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  discrete_df[column] = x[column]\n",
      "C:\\Users\\usuario\\AppData\\Local\\Temp\\ipykernel_10332\\2686454219.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  discrete_df[column] = x[column]\n",
      "C:\\Users\\usuario\\AppData\\Local\\Temp\\ipykernel_10332\\2686454219.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  discrete_df[column] = x[column]\n",
      "C:\\Users\\usuario\\AppData\\Local\\Temp\\ipykernel_10332\\2686454219.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  discrete_df[column] = x[column]\n",
      "C:\\Users\\usuario\\AppData\\Local\\Temp\\ipykernel_10332\\2686454219.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  discrete_df[column] = x[column]\n",
      "C:\\Users\\usuario\\AppData\\Local\\Temp\\ipykernel_10332\\2686454219.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  discrete_df[column] = x[column]\n",
      "C:\\Users\\usuario\\AppData\\Local\\Temp\\ipykernel_10332\\2686454219.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  discrete_df[column] = x[column]\n",
      "C:\\Users\\usuario\\AppData\\Local\\Temp\\ipykernel_10332\\2686454219.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  discrete_df[column] = x[column]\n",
      "C:\\Users\\usuario\\AppData\\Local\\Temp\\ipykernel_10332\\2686454219.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  discrete_df[column] = x[column]\n",
      "C:\\Users\\usuario\\AppData\\Local\\Temp\\ipykernel_10332\\2686454219.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  discrete_df[column] = x[column]\n",
      "C:\\Users\\usuario\\AppData\\Local\\Temp\\ipykernel_10332\\2686454219.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  discrete_df[column] = x[column]\n",
      "C:\\Users\\usuario\\AppData\\Local\\Temp\\ipykernel_10332\\2686454219.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  discrete_df[column] = x[column]\n",
      "C:\\Users\\usuario\\AppData\\Local\\Temp\\ipykernel_10332\\2686454219.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  discrete_df[column] = x[column]\n",
      "C:\\Users\\usuario\\AppData\\Local\\Temp\\ipykernel_10332\\2686454219.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  discrete_df[column] = x[column]\n",
      "C:\\Users\\usuario\\AppData\\Local\\Temp\\ipykernel_10332\\2686454219.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  discrete_df[column] = x[column]\n",
      "C:\\Users\\usuario\\AppData\\Local\\Temp\\ipykernel_10332\\2686454219.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  discrete_df[column] = x[column]\n",
      "C:\\Users\\usuario\\AppData\\Local\\Temp\\ipykernel_10332\\2686454219.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  discrete_df[column] = x[column]\n",
      "C:\\Users\\usuario\\AppData\\Local\\Temp\\ipykernel_10332\\2686454219.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  discrete_df[column] = x[column]\n",
      "C:\\Users\\usuario\\AppData\\Local\\Temp\\ipykernel_10332\\2686454219.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  discrete_df[column] = x[column]\n",
      "C:\\Users\\usuario\\AppData\\Local\\Temp\\ipykernel_10332\\2686454219.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  discrete_df[column] = x[column]\n",
      "C:\\Users\\usuario\\AppData\\Local\\Temp\\ipykernel_10332\\2686454219.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  discrete_df[column] = x[column]\n",
      "C:\\Users\\usuario\\AppData\\Local\\Temp\\ipykernel_10332\\2686454219.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  discrete_df[column] = x[column]\n",
      "C:\\Users\\usuario\\AppData\\Local\\Temp\\ipykernel_10332\\2686454219.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  discrete_df[column] = x[column]\n",
      "C:\\Users\\usuario\\AppData\\Local\\Temp\\ipykernel_10332\\2686454219.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  discrete_df[column] = x[column]\n",
      "C:\\Users\\usuario\\AppData\\Local\\Temp\\ipykernel_10332\\2686454219.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  discrete_df[column] = x[column]\n",
      "C:\\Users\\usuario\\AppData\\Local\\Temp\\ipykernel_10332\\2686454219.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  discrete_df[column] = x[column]\n",
      "C:\\Users\\usuario\\AppData\\Local\\Temp\\ipykernel_10332\\2686454219.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  discrete_df[column] = x[column]\n",
      "C:\\Users\\usuario\\AppData\\Local\\Temp\\ipykernel_10332\\2686454219.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  discrete_df[column] = x[column]\n",
      "C:\\Users\\usuario\\AppData\\Local\\Temp\\ipykernel_10332\\2686454219.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  discrete_df[column] = x[column]\n",
      "C:\\Users\\usuario\\AppData\\Local\\Temp\\ipykernel_10332\\2686454219.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  discrete_df[column] = x[column]\n",
      "C:\\Users\\usuario\\AppData\\Local\\Temp\\ipykernel_10332\\2686454219.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  discrete_df[column] = x[column]\n",
      "C:\\Users\\usuario\\AppData\\Local\\Temp\\ipykernel_10332\\2686454219.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  discrete_df[column] = x[column]\n",
      "C:\\Users\\usuario\\AppData\\Local\\Temp\\ipykernel_10332\\2686454219.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  discrete_df[column] = x[column]\n",
      "C:\\Users\\usuario\\AppData\\Local\\Temp\\ipykernel_10332\\2686454219.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  discrete_df[column] = x[column]\n",
      "C:\\Users\\usuario\\AppData\\Local\\Temp\\ipykernel_10332\\2686454219.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  discrete_df[column] = x[column]\n",
      "C:\\Users\\usuario\\AppData\\Local\\Temp\\ipykernel_10332\\2686454219.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  discrete_df[column] = x[column]\n",
      "C:\\Users\\usuario\\AppData\\Local\\Temp\\ipykernel_10332\\2686454219.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  discrete_df[column] = x[column]\n",
      "C:\\Users\\usuario\\AppData\\Local\\Temp\\ipykernel_10332\\2686454219.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  discrete_df[column] = x[column]\n",
      "C:\\Users\\usuario\\AppData\\Local\\Temp\\ipykernel_10332\\2686454219.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  discrete_df[column] = x[column]\n",
      "C:\\Users\\usuario\\AppData\\Local\\Temp\\ipykernel_10332\\2686454219.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  discrete_df[column] = x[column]\n",
      "C:\\Users\\usuario\\AppData\\Local\\Temp\\ipykernel_10332\\2686454219.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  discrete_df[column] = x[column]\n",
      "C:\\Users\\usuario\\AppData\\Local\\Temp\\ipykernel_10332\\2686454219.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  discrete_df[column] = x[column]\n",
      "C:\\Users\\usuario\\AppData\\Local\\Temp\\ipykernel_10332\\2686454219.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  discrete_df[column] = x[column]\n",
      "C:\\Users\\usuario\\AppData\\Local\\Temp\\ipykernel_10332\\2686454219.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  discrete_df[column] = x[column]\n",
      "C:\\Users\\usuario\\AppData\\Local\\Temp\\ipykernel_10332\\2686454219.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  discrete_df[column] = x[column]\n",
      "C:\\Users\\usuario\\AppData\\Local\\Temp\\ipykernel_10332\\2686454219.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  discrete_df[column] = x[column]\n",
      "C:\\Users\\usuario\\AppData\\Local\\Temp\\ipykernel_10332\\2686454219.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  discrete_df[column] = x[column]\n",
      "C:\\Users\\usuario\\AppData\\Local\\Temp\\ipykernel_10332\\2686454219.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  discrete_df[column] = x[column]\n",
      "C:\\Users\\usuario\\AppData\\Local\\Temp\\ipykernel_10332\\2686454219.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  discrete_df[column] = x[column]\n",
      "C:\\Users\\usuario\\AppData\\Local\\Temp\\ipykernel_10332\\2686454219.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  discrete_df[column] = x[column]\n",
      "C:\\Users\\usuario\\AppData\\Local\\Temp\\ipykernel_10332\\2686454219.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  discrete_df[column] = x[column]\n",
      "C:\\Users\\usuario\\AppData\\Local\\Temp\\ipykernel_10332\\2686454219.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  discrete_df[column] = x[column]\n",
      "C:\\Users\\usuario\\AppData\\Local\\Temp\\ipykernel_10332\\2686454219.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  discrete_df[column] = x[column]\n",
      "C:\\Users\\usuario\\AppData\\Local\\Temp\\ipykernel_10332\\2686454219.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  discrete_df[column] = x[column]\n",
      "C:\\Users\\usuario\\AppData\\Local\\Temp\\ipykernel_10332\\2686454219.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  discrete_df[column] = x[column]\n",
      "C:\\Users\\usuario\\AppData\\Local\\Temp\\ipykernel_10332\\2686454219.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  discrete_df[column] = x[column]\n",
      "C:\\Users\\usuario\\AppData\\Local\\Temp\\ipykernel_10332\\2686454219.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  discrete_df[column] = x[column]\n",
      "C:\\Users\\usuario\\AppData\\Local\\Temp\\ipykernel_10332\\2686454219.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  discrete_df[column] = x[column]\n",
      "C:\\Users\\usuario\\AppData\\Local\\Temp\\ipykernel_10332\\2686454219.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  discrete_df[column] = x[column]\n",
      "C:\\Users\\usuario\\AppData\\Local\\Temp\\ipykernel_10332\\2686454219.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  discrete_df[column] = x[column]\n",
      "C:\\Users\\usuario\\AppData\\Local\\Temp\\ipykernel_10332\\2686454219.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  discrete_df[column] = x[column]\n",
      "C:\\Users\\usuario\\AppData\\Local\\Temp\\ipykernel_10332\\2686454219.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  discrete_df[column] = x[column]\n",
      "C:\\Users\\usuario\\AppData\\Local\\Temp\\ipykernel_10332\\2686454219.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  discrete_df[column] = x[column]\n",
      "C:\\Users\\usuario\\AppData\\Local\\Temp\\ipykernel_10332\\2686454219.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  discrete_df[column] = x[column]\n",
      "C:\\Users\\usuario\\AppData\\Local\\Temp\\ipykernel_10332\\2686454219.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  discrete_df[column] = x[column]\n",
      "C:\\Users\\usuario\\AppData\\Local\\Temp\\ipykernel_10332\\2686454219.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  discrete_df[column] = x[column]\n",
      "C:\\Users\\usuario\\AppData\\Local\\Temp\\ipykernel_10332\\2686454219.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  discrete_df[column] = x[column]\n",
      "C:\\Users\\usuario\\AppData\\Local\\Temp\\ipykernel_10332\\2686454219.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  discrete_df[column] = x[column]\n",
      "C:\\Users\\usuario\\AppData\\Local\\Temp\\ipykernel_10332\\2686454219.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  discrete_df[column] = x[column]\n",
      "C:\\Users\\usuario\\AppData\\Local\\Temp\\ipykernel_10332\\2686454219.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  discrete_df[column] = x[column]\n",
      "C:\\Users\\usuario\\AppData\\Local\\Temp\\ipykernel_10332\\2686454219.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  discrete_df[column] = x[column]\n",
      "C:\\Users\\usuario\\AppData\\Local\\Temp\\ipykernel_10332\\2686454219.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  discrete_df[column] = x[column]\n",
      "C:\\Users\\usuario\\AppData\\Local\\Temp\\ipykernel_10332\\2686454219.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  discrete_df[column] = x[column]\n",
      "C:\\Users\\usuario\\AppData\\Local\\Temp\\ipykernel_10332\\2686454219.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  discrete_df[column] = x[column]\n",
      "C:\\Users\\usuario\\AppData\\Local\\Temp\\ipykernel_10332\\2686454219.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  discrete_df[column] = x[column]\n",
      "C:\\Users\\usuario\\AppData\\Local\\Temp\\ipykernel_10332\\2686454219.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  discrete_df[column] = x[column]\n",
      "C:\\Users\\usuario\\AppData\\Local\\Temp\\ipykernel_10332\\2686454219.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  discrete_df[column] = x[column]\n",
      "C:\\Users\\usuario\\AppData\\Local\\Temp\\ipykernel_10332\\2686454219.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  discrete_df[column] = x[column]\n",
      "C:\\Users\\usuario\\AppData\\Local\\Temp\\ipykernel_10332\\2686454219.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  discrete_df[column] = x[column]\n",
      "C:\\Users\\usuario\\AppData\\Local\\Temp\\ipykernel_10332\\2686454219.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  discrete_df[column] = x[column]\n",
      "C:\\Users\\usuario\\AppData\\Local\\Temp\\ipykernel_10332\\2686454219.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  discrete_df[column] = x[column]\n",
      "C:\\Users\\usuario\\AppData\\Local\\Temp\\ipykernel_10332\\2686454219.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  discrete_df[column] = x[column]\n",
      "C:\\Users\\usuario\\AppData\\Local\\Temp\\ipykernel_10332\\2686454219.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  discrete_df[column] = x[column]\n",
      "C:\\Users\\usuario\\AppData\\Local\\Temp\\ipykernel_10332\\2686454219.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  discrete_df[column] = x[column]\n",
      "C:\\Users\\usuario\\AppData\\Local\\Temp\\ipykernel_10332\\2686454219.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  discrete_df[column] = x[column]\n",
      "C:\\Users\\usuario\\AppData\\Local\\Temp\\ipykernel_10332\\2686454219.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  discrete_df[column] = x[column]\n",
      "C:\\Users\\usuario\\AppData\\Local\\Temp\\ipykernel_10332\\2686454219.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  discrete_df[column] = x[column]\n",
      "C:\\Users\\usuario\\AppData\\Local\\Temp\\ipykernel_10332\\2686454219.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  discrete_df[column] = x[column]\n",
      "C:\\Users\\usuario\\AppData\\Local\\Temp\\ipykernel_10332\\2686454219.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  discrete_df[column] = x[column]\n",
      "C:\\Users\\usuario\\AppData\\Local\\Temp\\ipykernel_10332\\2686454219.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  discrete_df[column] = x[column]\n",
      "C:\\Users\\usuario\\AppData\\Local\\Temp\\ipykernel_10332\\2686454219.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  discrete_df[column] = x[column]\n",
      "C:\\Users\\usuario\\AppData\\Local\\Temp\\ipykernel_10332\\2686454219.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  discrete_df[column] = x[column]\n",
      "C:\\Users\\usuario\\AppData\\Local\\Temp\\ipykernel_10332\\2686454219.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  discrete_df[column] = x[column]\n",
      "C:\\Users\\usuario\\AppData\\Local\\Temp\\ipykernel_10332\\2686454219.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  discrete_df[column] = x[column]\n",
      "C:\\Users\\usuario\\AppData\\Local\\Temp\\ipykernel_10332\\2686454219.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  discrete_df[column] = x[column]\n",
      "C:\\Users\\usuario\\AppData\\Local\\Temp\\ipykernel_10332\\2686454219.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  discrete_df[column] = x[column]\n",
      "C:\\Users\\usuario\\AppData\\Local\\Temp\\ipykernel_10332\\2686454219.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  discrete_df[column] = x[column]\n",
      "C:\\Users\\usuario\\AppData\\Local\\Temp\\ipykernel_10332\\2686454219.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  discrete_df[column] = x[column]\n",
      "C:\\Users\\usuario\\AppData\\Local\\Temp\\ipykernel_10332\\2686454219.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  discrete_df[column] = x[column]\n",
      "C:\\Users\\usuario\\AppData\\Local\\Temp\\ipykernel_10332\\2686454219.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  discrete_df[column] = x[column]\n",
      "C:\\Users\\usuario\\AppData\\Local\\Temp\\ipykernel_10332\\2686454219.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  discrete_df[column] = x[column]\n",
      "C:\\Users\\usuario\\AppData\\Local\\Temp\\ipykernel_10332\\2686454219.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  discrete_df[column] = x[column]\n",
      "C:\\Users\\usuario\\AppData\\Local\\Temp\\ipykernel_10332\\2686454219.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  discrete_df[column] = x[column]\n",
      "C:\\Users\\usuario\\AppData\\Local\\Temp\\ipykernel_10332\\2686454219.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  discrete_df[column] = x[column]\n",
      "C:\\Users\\usuario\\AppData\\Local\\Temp\\ipykernel_10332\\2686454219.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  discrete_df[column] = x[column]\n",
      "C:\\Users\\usuario\\AppData\\Local\\Temp\\ipykernel_10332\\2686454219.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  discrete_df[column] = x[column]\n",
      "C:\\Users\\usuario\\AppData\\Local\\Temp\\ipykernel_10332\\2686454219.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  discrete_df[column] = x[column]\n",
      "C:\\Users\\usuario\\AppData\\Local\\Temp\\ipykernel_10332\\2686454219.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  discrete_df[column] = x[column]\n",
      "C:\\Users\\usuario\\AppData\\Local\\Temp\\ipykernel_10332\\2686454219.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  discrete_df[column] = x[column]\n",
      "C:\\Users\\usuario\\AppData\\Local\\Temp\\ipykernel_10332\\2686454219.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  discrete_df[column] = x[column]\n",
      "C:\\Users\\usuario\\AppData\\Local\\Temp\\ipykernel_10332\\2686454219.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  discrete_df[column] = x[column]\n",
      "C:\\Users\\usuario\\AppData\\Local\\Temp\\ipykernel_10332\\2686454219.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  discrete_df[column] = x[column]\n",
      "C:\\Users\\usuario\\AppData\\Local\\Temp\\ipykernel_10332\\2686454219.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  discrete_df[column] = x[column]\n",
      "C:\\Users\\usuario\\AppData\\Local\\Temp\\ipykernel_10332\\2686454219.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  discrete_df[column] = x[column]\n",
      "C:\\Users\\usuario\\AppData\\Local\\Temp\\ipykernel_10332\\2686454219.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  discrete_df[column] = x[column]\n",
      "C:\\Users\\usuario\\AppData\\Local\\Temp\\ipykernel_10332\\2686454219.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  discrete_df[column] = x[column]\n",
      "C:\\Users\\usuario\\AppData\\Local\\Temp\\ipykernel_10332\\2686454219.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  discrete_df[column] = x[column]\n",
      "C:\\Users\\usuario\\AppData\\Local\\Temp\\ipykernel_10332\\2686454219.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  discrete_df[column] = x[column]\n",
      "C:\\Users\\usuario\\AppData\\Local\\Temp\\ipykernel_10332\\2686454219.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  discrete_df[column] = x[column]\n",
      "C:\\Users\\usuario\\AppData\\Local\\Temp\\ipykernel_10332\\2686454219.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  discrete_df[column] = x[column]\n",
      "C:\\Users\\usuario\\AppData\\Local\\Temp\\ipykernel_10332\\2686454219.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  discrete_df[column] = x[column]\n",
      "C:\\Users\\usuario\\AppData\\Local\\Temp\\ipykernel_10332\\2686454219.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  discrete_df[column] = x[column]\n",
      "C:\\Users\\usuario\\AppData\\Local\\Temp\\ipykernel_10332\\2686454219.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  discrete_df[column] = x[column]\n",
      "C:\\Users\\usuario\\AppData\\Local\\Temp\\ipykernel_10332\\2686454219.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  discrete_df[column] = x[column]\n",
      "C:\\Users\\usuario\\AppData\\Local\\Temp\\ipykernel_10332\\2686454219.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  discrete_df[column] = x[column]\n",
      "C:\\Users\\usuario\\AppData\\Local\\Temp\\ipykernel_10332\\2686454219.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  discrete_df[column] = x[column]\n",
      "C:\\Users\\usuario\\AppData\\Local\\Temp\\ipykernel_10332\\2686454219.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  discrete_df[column] = x[column]\n",
      "C:\\Users\\usuario\\AppData\\Local\\Temp\\ipykernel_10332\\2686454219.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  discrete_df[column] = x[column]\n",
      "C:\\Users\\usuario\\AppData\\Local\\Temp\\ipykernel_10332\\2686454219.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  discrete_df[column] = x[column]\n",
      "C:\\Users\\usuario\\AppData\\Local\\Temp\\ipykernel_10332\\2686454219.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  discrete_df[column] = x[column]\n",
      "C:\\Users\\usuario\\AppData\\Local\\Temp\\ipykernel_10332\\2686454219.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  discrete_df[column] = x[column]\n",
      "C:\\Users\\usuario\\AppData\\Local\\Temp\\ipykernel_10332\\2686454219.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  discrete_df[column] = x[column]\n",
      "C:\\Users\\usuario\\AppData\\Local\\Temp\\ipykernel_10332\\2686454219.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  discrete_df[column] = x[column]\n",
      "C:\\Users\\usuario\\AppData\\Local\\Temp\\ipykernel_10332\\2686454219.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  discrete_df[column] = x[column]\n",
      "C:\\Users\\usuario\\AppData\\Local\\Temp\\ipykernel_10332\\2686454219.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  discrete_df[column] = x[column]\n",
      "C:\\Users\\usuario\\AppData\\Local\\Temp\\ipykernel_10332\\2686454219.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  discrete_df[column] = x[column]\n",
      "C:\\Users\\usuario\\AppData\\Local\\Temp\\ipykernel_10332\\2686454219.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  discrete_df[column] = x[column]\n",
      "C:\\Users\\usuario\\AppData\\Local\\Temp\\ipykernel_10332\\2686454219.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  discrete_df[column] = x[column]\n",
      "C:\\Users\\usuario\\AppData\\Local\\Temp\\ipykernel_10332\\2686454219.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  discrete_df[column] = x[column]\n",
      "C:\\Users\\usuario\\AppData\\Local\\Temp\\ipykernel_10332\\2686454219.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  discrete_df[column] = x[column]\n",
      "C:\\Users\\usuario\\AppData\\Local\\Temp\\ipykernel_10332\\2686454219.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  discrete_df[column] = x[column]\n",
      "C:\\Users\\usuario\\AppData\\Local\\Temp\\ipykernel_10332\\2686454219.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  discrete_df[column] = x[column]\n",
      "C:\\Users\\usuario\\AppData\\Local\\Temp\\ipykernel_10332\\2686454219.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  discrete_df[column] = x[column]\n",
      "C:\\Users\\usuario\\AppData\\Local\\Temp\\ipykernel_10332\\2686454219.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  discrete_df[column] = x[column]\n",
      "C:\\Users\\usuario\\AppData\\Local\\Temp\\ipykernel_10332\\2686454219.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  discrete_df[column] = x[column]\n",
      "C:\\Users\\usuario\\AppData\\Local\\Temp\\ipykernel_10332\\2686454219.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  discrete_df[column] = x[column]\n",
      "C:\\Users\\usuario\\AppData\\Local\\Temp\\ipykernel_10332\\2686454219.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  discrete_df[column] = x[column]\n",
      "C:\\Users\\usuario\\AppData\\Local\\Temp\\ipykernel_10332\\2686454219.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  discrete_df[column] = x[column]\n",
      "C:\\Users\\usuario\\AppData\\Local\\Temp\\ipykernel_10332\\2686454219.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  discrete_df[column] = x[column]\n",
      "C:\\Users\\usuario\\AppData\\Local\\Temp\\ipykernel_10332\\2686454219.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  discrete_df[column] = x[column]\n",
      "C:\\Users\\usuario\\AppData\\Local\\Temp\\ipykernel_10332\\2686454219.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  discrete_df[column] = x[column]\n",
      "C:\\Users\\usuario\\AppData\\Local\\Temp\\ipykernel_10332\\2686454219.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  discrete_df[column] = x[column]\n",
      "C:\\Users\\usuario\\AppData\\Local\\Temp\\ipykernel_10332\\2686454219.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  discrete_df[column] = x[column]\n",
      "C:\\Users\\usuario\\AppData\\Local\\Temp\\ipykernel_10332\\2686454219.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  discrete_df[column] = x[column]\n",
      "C:\\Users\\usuario\\AppData\\Local\\Temp\\ipykernel_10332\\2686454219.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  discrete_df[column] = x[column]\n",
      "C:\\Users\\usuario\\AppData\\Local\\Temp\\ipykernel_10332\\2686454219.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  discrete_df[column] = x[column]\n",
      "C:\\Users\\usuario\\AppData\\Local\\Temp\\ipykernel_10332\\2686454219.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  discrete_df[column] = x[column]\n",
      "C:\\Users\\usuario\\AppData\\Local\\Temp\\ipykernel_10332\\2686454219.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  discrete_df[column] = x[column]\n",
      "C:\\Users\\usuario\\AppData\\Local\\Temp\\ipykernel_10332\\2686454219.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  discrete_df[column] = x[column]\n",
      "C:\\Users\\usuario\\AppData\\Local\\Temp\\ipykernel_10332\\2686454219.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  discrete_df[column] = x[column]\n",
      "C:\\Users\\usuario\\AppData\\Local\\Temp\\ipykernel_10332\\2686454219.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  discrete_df[column] = x[column]\n",
      "C:\\Users\\usuario\\AppData\\Local\\Temp\\ipykernel_10332\\2686454219.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  discrete_df[column] = x[column]\n",
      "C:\\Users\\usuario\\AppData\\Local\\Temp\\ipykernel_10332\\2686454219.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  discrete_df[column] = x[column]\n",
      "C:\\Users\\usuario\\AppData\\Local\\Temp\\ipykernel_10332\\2686454219.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  discrete_df[column] = x[column]\n",
      "C:\\Users\\usuario\\AppData\\Local\\Temp\\ipykernel_10332\\2686454219.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  discrete_df[column] = x[column]\n",
      "C:\\Users\\usuario\\AppData\\Local\\Temp\\ipykernel_10332\\2686454219.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  discrete_df[column] = x[column]\n",
      "C:\\Users\\usuario\\AppData\\Local\\Temp\\ipykernel_10332\\2686454219.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  discrete_df[column] = x[column]\n",
      "C:\\Users\\usuario\\AppData\\Local\\Temp\\ipykernel_10332\\2686454219.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  discrete_df[column] = x[column]\n",
      "C:\\Users\\usuario\\AppData\\Local\\Temp\\ipykernel_10332\\2686454219.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  discrete_df[column] = x[column]\n",
      "C:\\Users\\usuario\\AppData\\Local\\Temp\\ipykernel_10332\\2686454219.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  discrete_df[column] = x[column]\n",
      "C:\\Users\\usuario\\AppData\\Local\\Temp\\ipykernel_10332\\2686454219.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  discrete_df[column] = x[column]\n",
      "C:\\Users\\usuario\\AppData\\Local\\Temp\\ipykernel_10332\\2686454219.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  discrete_df[column] = x[column]\n",
      "C:\\Users\\usuario\\AppData\\Local\\Temp\\ipykernel_10332\\2686454219.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  discrete_df[column] = x[column]\n",
      "C:\\Users\\usuario\\AppData\\Local\\Temp\\ipykernel_10332\\2686454219.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  discrete_df[column] = x[column]\n",
      "C:\\Users\\usuario\\AppData\\Local\\Temp\\ipykernel_10332\\2686454219.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  discrete_df[column] = x[column]\n",
      "C:\\Users\\usuario\\AppData\\Local\\Temp\\ipykernel_10332\\2686454219.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  discrete_df[column] = x[column]\n",
      "C:\\Users\\usuario\\AppData\\Local\\Temp\\ipykernel_10332\\2686454219.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  discrete_df[column] = x[column]\n",
      "C:\\Users\\usuario\\AppData\\Local\\Temp\\ipykernel_10332\\2686454219.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  discrete_df[column] = x[column]\n",
      "C:\\Users\\usuario\\AppData\\Local\\Temp\\ipykernel_10332\\2686454219.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  discrete_df[column] = x[column]\n",
      "C:\\Users\\usuario\\AppData\\Local\\Temp\\ipykernel_10332\\2686454219.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  discrete_df[column] = x[column]\n",
      "C:\\Users\\usuario\\AppData\\Local\\Temp\\ipykernel_10332\\2686454219.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  discrete_df[column] = x[column]\n",
      "C:\\Users\\usuario\\AppData\\Local\\Temp\\ipykernel_10332\\2686454219.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  discrete_df[column] = x[column]\n",
      "C:\\Users\\usuario\\AppData\\Local\\Temp\\ipykernel_10332\\2686454219.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  discrete_df[column] = x[column]\n",
      "C:\\Users\\usuario\\AppData\\Local\\Temp\\ipykernel_10332\\2686454219.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  discrete_df[column] = x[column]\n",
      "C:\\Users\\usuario\\AppData\\Local\\Temp\\ipykernel_10332\\2686454219.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  discrete_df[column] = x[column]\n",
      "C:\\Users\\usuario\\AppData\\Local\\Temp\\ipykernel_10332\\2686454219.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  discrete_df[column] = x[column]\n",
      "C:\\Users\\usuario\\AppData\\Local\\Temp\\ipykernel_10332\\2686454219.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  discrete_df[column] = x[column]\n",
      "C:\\Users\\usuario\\AppData\\Local\\Temp\\ipykernel_10332\\2686454219.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  discrete_df[column] = x[column]\n",
      "C:\\Users\\usuario\\AppData\\Local\\Temp\\ipykernel_10332\\2686454219.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  discrete_df[column] = x[column]\n",
      "C:\\Users\\usuario\\AppData\\Local\\Temp\\ipykernel_10332\\2686454219.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  discrete_df[column] = x[column]\n",
      "C:\\Users\\usuario\\AppData\\Local\\Temp\\ipykernel_10332\\2686454219.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  discrete_df[column] = x[column]\n",
      "C:\\Users\\usuario\\AppData\\Local\\Temp\\ipykernel_10332\\2686454219.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  discrete_df[column] = x[column]\n",
      "C:\\Users\\usuario\\AppData\\Local\\Temp\\ipykernel_10332\\2686454219.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  discrete_df[column] = x[column]\n",
      "C:\\Users\\usuario\\AppData\\Local\\Temp\\ipykernel_10332\\2686454219.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  discrete_df[column] = x[column]\n",
      "C:\\Users\\usuario\\AppData\\Local\\Temp\\ipykernel_10332\\2686454219.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  discrete_df[column] = x[column]\n",
      "C:\\Users\\usuario\\AppData\\Local\\Temp\\ipykernel_10332\\2686454219.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  discrete_df[column] = x[column]\n",
      "C:\\Users\\usuario\\AppData\\Local\\Temp\\ipykernel_10332\\2686454219.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  discrete_df[column] = x[column]\n",
      "C:\\Users\\usuario\\AppData\\Local\\Temp\\ipykernel_10332\\2686454219.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  discrete_df[column] = x[column]\n",
      "C:\\Users\\usuario\\AppData\\Local\\Temp\\ipykernel_10332\\2686454219.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  discrete_df[column] = x[column]\n",
      "C:\\Users\\usuario\\AppData\\Local\\Temp\\ipykernel_10332\\2686454219.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  discrete_df[column] = x[column]\n",
      "C:\\Users\\usuario\\AppData\\Local\\Temp\\ipykernel_10332\\2686454219.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  discrete_df[column] = x[column]\n",
      "C:\\Users\\usuario\\AppData\\Local\\Temp\\ipykernel_10332\\2686454219.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  discrete_df[column] = x[column]\n"
     ]
    }
   ],
   "source": [
    "# call the function to separate discrete and continuous\n",
    "continuous_df, discrete_df = diff_variable(numerical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>POP901</th>\n",
       "      <th>POP902</th>\n",
       "      <th>POP903</th>\n",
       "      <th>HV1</th>\n",
       "      <th>HV2</th>\n",
       "      <th>IC5</th>\n",
       "      <th>AVGGIFT</th>\n",
       "      <th>CONTROLN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>992</td>\n",
       "      <td>264</td>\n",
       "      <td>332</td>\n",
       "      <td>479</td>\n",
       "      <td>635</td>\n",
       "      <td>12883</td>\n",
       "      <td>7.741935</td>\n",
       "      <td>95515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3611</td>\n",
       "      <td>940</td>\n",
       "      <td>998</td>\n",
       "      <td>5468</td>\n",
       "      <td>5218</td>\n",
       "      <td>36175</td>\n",
       "      <td>15.666667</td>\n",
       "      <td>148535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7001</td>\n",
       "      <td>2040</td>\n",
       "      <td>2669</td>\n",
       "      <td>497</td>\n",
       "      <td>546</td>\n",
       "      <td>11576</td>\n",
       "      <td>7.481481</td>\n",
       "      <td>15078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>640</td>\n",
       "      <td>160</td>\n",
       "      <td>219</td>\n",
       "      <td>1000</td>\n",
       "      <td>1263</td>\n",
       "      <td>15130</td>\n",
       "      <td>6.812500</td>\n",
       "      <td>172556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2520</td>\n",
       "      <td>627</td>\n",
       "      <td>761</td>\n",
       "      <td>576</td>\n",
       "      <td>594</td>\n",
       "      <td>9836</td>\n",
       "      <td>6.864865</td>\n",
       "      <td>7112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95407</th>\n",
       "      <td>27380</td>\n",
       "      <td>7252</td>\n",
       "      <td>10037</td>\n",
       "      <td>988</td>\n",
       "      <td>1025</td>\n",
       "      <td>18807</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>184568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95408</th>\n",
       "      <td>1254</td>\n",
       "      <td>322</td>\n",
       "      <td>361</td>\n",
       "      <td>1679</td>\n",
       "      <td>1723</td>\n",
       "      <td>26538</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>122706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95409</th>\n",
       "      <td>552</td>\n",
       "      <td>131</td>\n",
       "      <td>205</td>\n",
       "      <td>376</td>\n",
       "      <td>377</td>\n",
       "      <td>12178</td>\n",
       "      <td>8.285714</td>\n",
       "      <td>189641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95410</th>\n",
       "      <td>1746</td>\n",
       "      <td>432</td>\n",
       "      <td>508</td>\n",
       "      <td>2421</td>\n",
       "      <td>2459</td>\n",
       "      <td>15948</td>\n",
       "      <td>12.146341</td>\n",
       "      <td>4693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95411</th>\n",
       "      <td>3935</td>\n",
       "      <td>1192</td>\n",
       "      <td>1342</td>\n",
       "      <td>938</td>\n",
       "      <td>1049</td>\n",
       "      <td>16699</td>\n",
       "      <td>96.794872</td>\n",
       "      <td>185114</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>95412 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       POP901  POP902  POP903   HV1   HV2    IC5    AVGGIFT  CONTROLN\n",
       "0         992     264     332   479   635  12883   7.741935     95515\n",
       "1        3611     940     998  5468  5218  36175  15.666667    148535\n",
       "2        7001    2040    2669   497   546  11576   7.481481     15078\n",
       "3         640     160     219  1000  1263  15130   6.812500    172556\n",
       "4        2520     627     761   576   594   9836   6.864865      7112\n",
       "...       ...     ...     ...   ...   ...    ...        ...       ...\n",
       "95407   27380    7252   10037   988  1025  18807  25.000000    184568\n",
       "95408    1254     322     361  1679  1723  26538  20.000000    122706\n",
       "95409     552     131     205   376   377  12178   8.285714    189641\n",
       "95410    1746     432     508  2421  2459  15948  12.146341      4693\n",
       "95411    3935    1192    1342   938  1049  16699  96.794872    185114\n",
       "\n",
       "[95412 rows x 8 columns]"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "continuous_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ODATEDW</th>\n",
       "      <th>TCODE</th>\n",
       "      <th>DOB</th>\n",
       "      <th>AGE</th>\n",
       "      <th>NUMCHLD</th>\n",
       "      <th>INCOME</th>\n",
       "      <th>WEALTH1</th>\n",
       "      <th>HIT</th>\n",
       "      <th>MBCRAFT</th>\n",
       "      <th>MBGARDEN</th>\n",
       "      <th>...</th>\n",
       "      <th>NUMPRM12</th>\n",
       "      <th>NGIFTALL</th>\n",
       "      <th>CARDGIFT</th>\n",
       "      <th>LASTGIFT</th>\n",
       "      <th>LASTDATE</th>\n",
       "      <th>FISTDATE</th>\n",
       "      <th>TIMELAG</th>\n",
       "      <th>HPHONE_D</th>\n",
       "      <th>RFA_2F</th>\n",
       "      <th>CLUSTER2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8901</td>\n",
       "      <td>0</td>\n",
       "      <td>3712</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>14</td>\n",
       "      <td>31</td>\n",
       "      <td>14</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9512</td>\n",
       "      <td>8911</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>39.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9401</td>\n",
       "      <td>1</td>\n",
       "      <td>5202</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>25.0</td>\n",
       "      <td>9512</td>\n",
       "      <td>9310</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9001</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>61.611649</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>14</td>\n",
       "      <td>27</td>\n",
       "      <td>14</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9512</td>\n",
       "      <td>9001</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>60.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8701</td>\n",
       "      <td>0</td>\n",
       "      <td>2801</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>14</td>\n",
       "      <td>16</td>\n",
       "      <td>7</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9512</td>\n",
       "      <td>8702</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>41.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8601</td>\n",
       "      <td>0</td>\n",
       "      <td>2001</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>60</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>25</td>\n",
       "      <td>37</td>\n",
       "      <td>8</td>\n",
       "      <td>15.0</td>\n",
       "      <td>9601</td>\n",
       "      <td>7903</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95407</th>\n",
       "      <td>9601</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>61.611649</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>9602</td>\n",
       "      <td>9602</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95408</th>\n",
       "      <td>9601</td>\n",
       "      <td>1</td>\n",
       "      <td>5001</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>9603</td>\n",
       "      <td>9603</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95409</th>\n",
       "      <td>9501</td>\n",
       "      <td>1</td>\n",
       "      <td>3801</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>17</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9610</td>\n",
       "      <td>9410</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>34.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95410</th>\n",
       "      <td>8601</td>\n",
       "      <td>0</td>\n",
       "      <td>4005</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>31</td>\n",
       "      <td>41</td>\n",
       "      <td>18</td>\n",
       "      <td>18.0</td>\n",
       "      <td>9701</td>\n",
       "      <td>8612</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95411</th>\n",
       "      <td>8801</td>\n",
       "      <td>2</td>\n",
       "      <td>1801</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>35</td>\n",
       "      <td>39</td>\n",
       "      <td>11</td>\n",
       "      <td>100.0</td>\n",
       "      <td>9612</td>\n",
       "      <td>8803</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>95412 rows × 323 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       ODATEDW  TCODE   DOB        AGE  NUMCHLD  INCOME  WEALTH1  HIT  \\\n",
       "0         8901      0  3712  60.000000      0.0     5.0      5.0    0   \n",
       "1         9401      1  5202  46.000000      1.0     6.0      9.0   16   \n",
       "2         9001      1     0  61.611649      0.0     3.0      1.0    2   \n",
       "3         8701      0  2801  70.000000      0.0     1.0      4.0    2   \n",
       "4         8601      0  2001  78.000000      1.0     3.0      2.0   60   \n",
       "...        ...    ...   ...        ...      ...     ...      ...  ...   \n",
       "95407     9601      1     0  61.611649      0.0     5.0      5.0    0   \n",
       "95408     9601      1  5001  48.000000      1.0     7.0      9.0    1   \n",
       "95409     9501      1  3801  60.000000      0.0     5.0      5.0    0   \n",
       "95410     8601      0  4005  58.000000      0.0     7.0      5.0    0   \n",
       "95411     8801      2  1801  80.000000      0.0     5.0      8.0    3   \n",
       "\n",
       "       MBCRAFT  MBGARDEN  ...  NUMPRM12  NGIFTALL  CARDGIFT  LASTGIFT  \\\n",
       "0          0.0       0.0  ...        14        31        14      10.0   \n",
       "1          0.0       0.0  ...        13         3         1      25.0   \n",
       "2          0.0       0.0  ...        14        27        14       5.0   \n",
       "3          0.0       0.0  ...        14        16         7      10.0   \n",
       "4          1.0       0.0  ...        25        37         8      15.0   \n",
       "...        ...       ...  ...       ...       ...       ...       ...   \n",
       "95407      0.0       0.0  ...        12         1         0      25.0   \n",
       "95408      0.0       0.0  ...         8         1         0      20.0   \n",
       "95409      0.0       0.0  ...        17         7         4      10.0   \n",
       "95410      0.0       0.0  ...        31        41        18      18.0   \n",
       "95411      0.0       0.0  ...        35        39        11     100.0   \n",
       "\n",
       "       LASTDATE  FISTDATE  TIMELAG  HPHONE_D  RFA_2F  CLUSTER2  \n",
       "0          9512      8911      4.0         0       4      39.0  \n",
       "1          9512      9310     18.0         0       2       1.0  \n",
       "2          9512      9001     12.0         1       4      60.0  \n",
       "3          9512      8702      9.0         1       4      41.0  \n",
       "4          9601      7903     14.0         1       2      26.0  \n",
       "...         ...       ...      ...       ...     ...       ...  \n",
       "95407      9602      9602      9.0         0       1      12.0  \n",
       "95408      9603      9603      9.0         1       1       2.0  \n",
       "95409      9610      9410      3.0         1       3      34.0  \n",
       "95410      9701      8612      4.0         1       4      11.0  \n",
       "95411      9612      8803      6.0         1       1      12.0  \n",
       "\n",
       "[95412 rows x 323 columns]"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "discrete_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9501    15358\n",
       "8601    14596\n",
       "9401    12065\n",
       "9601    10122\n",
       "9101     8552\n",
       "9001     7718\n",
       "9201     7539\n",
       "8801     6669\n",
       "8901     5342\n",
       "9301     3921\n",
       "8701     3451\n",
       "9701       15\n",
       "9509        4\n",
       "9209        4\n",
       "9212        3\n",
       "9410        3\n",
       "9510        3\n",
       "8912        2\n",
       "9109        2\n",
       "9310        2\n",
       "8501        2\n",
       "9506        2\n",
       "9309        2\n",
       "8910        2\n",
       "9009        2\n",
       "9202        2\n",
       "9302        2\n",
       "9003        1\n",
       "9205        1\n",
       "8909        1\n",
       "9402        1\n",
       "9011        1\n",
       "8707        1\n",
       "9012        1\n",
       "8612        1\n",
       "8604        1\n",
       "9312        1\n",
       "9303        1\n",
       "8401        1\n",
       "9103        1\n",
       "8609        1\n",
       "8702        1\n",
       "9512        1\n",
       "8704        1\n",
       "9010        1\n",
       "8611        1\n",
       "8711        1\n",
       "9102        1\n",
       "8608        1\n",
       "9111        1\n",
       "9511        1\n",
       "8810        1\n",
       "8804        1\n",
       "8306        1\n",
       "Name: ODATEDW, dtype: int64"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "discrete_df['ODATEDW'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concat numerical and categorical columns\n",
    "X = pd.concat([numerical,categorical], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop target d\n",
    "y_d=target.drop(columns= ['TARGET_D'])\n",
    "y = pd.DataFrame(y_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop unnamed column \n",
    "\n",
    "y = y.drop(columns=['Unnamed: 0'])\n",
    "y = y.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ODATEDW</th>\n",
       "      <th>TCODE</th>\n",
       "      <th>DOB</th>\n",
       "      <th>AGE</th>\n",
       "      <th>NUMCHLD</th>\n",
       "      <th>INCOME</th>\n",
       "      <th>WEALTH1</th>\n",
       "      <th>HIT</th>\n",
       "      <th>MBCRAFT</th>\n",
       "      <th>MBGARDEN</th>\n",
       "      <th>...</th>\n",
       "      <th>STATE</th>\n",
       "      <th>CLUSTER</th>\n",
       "      <th>HOMEOWNR</th>\n",
       "      <th>GENDER</th>\n",
       "      <th>DATASRCE</th>\n",
       "      <th>RFA_2R</th>\n",
       "      <th>RFA_2A</th>\n",
       "      <th>GEOCODE2</th>\n",
       "      <th>DOMAIN_A</th>\n",
       "      <th>DOMAIN_B</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8901</td>\n",
       "      <td>0</td>\n",
       "      <td>3712</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>IL</td>\n",
       "      <td>36</td>\n",
       "      <td>N</td>\n",
       "      <td>F</td>\n",
       "      <td>0</td>\n",
       "      <td>L</td>\n",
       "      <td>E</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9401</td>\n",
       "      <td>1</td>\n",
       "      <td>5202</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>CA</td>\n",
       "      <td>14</td>\n",
       "      <td>H</td>\n",
       "      <td>M</td>\n",
       "      <td>3</td>\n",
       "      <td>L</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9001</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>61.611649</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NC</td>\n",
       "      <td>43</td>\n",
       "      <td>U</td>\n",
       "      <td>M</td>\n",
       "      <td>3</td>\n",
       "      <td>L</td>\n",
       "      <td>E</td>\n",
       "      <td>C</td>\n",
       "      <td>R</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8701</td>\n",
       "      <td>0</td>\n",
       "      <td>2801</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>CA</td>\n",
       "      <td>44</td>\n",
       "      <td>U</td>\n",
       "      <td>F</td>\n",
       "      <td>3</td>\n",
       "      <td>L</td>\n",
       "      <td>E</td>\n",
       "      <td>C</td>\n",
       "      <td>R</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8601</td>\n",
       "      <td>0</td>\n",
       "      <td>2001</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>60</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>FL</td>\n",
       "      <td>16</td>\n",
       "      <td>H</td>\n",
       "      <td>F</td>\n",
       "      <td>3</td>\n",
       "      <td>L</td>\n",
       "      <td>F</td>\n",
       "      <td>A</td>\n",
       "      <td>S</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95407</th>\n",
       "      <td>9601</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>61.611649</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>other</td>\n",
       "      <td>27</td>\n",
       "      <td>N</td>\n",
       "      <td>M</td>\n",
       "      <td>0</td>\n",
       "      <td>L</td>\n",
       "      <td>G</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95408</th>\n",
       "      <td>9601</td>\n",
       "      <td>1</td>\n",
       "      <td>5001</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>TX</td>\n",
       "      <td>24</td>\n",
       "      <td>H</td>\n",
       "      <td>M</td>\n",
       "      <td>3</td>\n",
       "      <td>L</td>\n",
       "      <td>F</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95409</th>\n",
       "      <td>9501</td>\n",
       "      <td>1</td>\n",
       "      <td>3801</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>MI</td>\n",
       "      <td>30</td>\n",
       "      <td>N</td>\n",
       "      <td>M</td>\n",
       "      <td>0</td>\n",
       "      <td>L</td>\n",
       "      <td>E</td>\n",
       "      <td>B</td>\n",
       "      <td>C</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95410</th>\n",
       "      <td>8601</td>\n",
       "      <td>0</td>\n",
       "      <td>4005</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>CA</td>\n",
       "      <td>24</td>\n",
       "      <td>H</td>\n",
       "      <td>F</td>\n",
       "      <td>2</td>\n",
       "      <td>L</td>\n",
       "      <td>F</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95411</th>\n",
       "      <td>8801</td>\n",
       "      <td>2</td>\n",
       "      <td>1801</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NC</td>\n",
       "      <td>24</td>\n",
       "      <td>U</td>\n",
       "      <td>F</td>\n",
       "      <td>3</td>\n",
       "      <td>L</td>\n",
       "      <td>G</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>95412 rows × 341 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       ODATEDW  TCODE   DOB        AGE  NUMCHLD  INCOME  WEALTH1  HIT  \\\n",
       "0         8901      0  3712  60.000000      0.0     5.0      5.0    0   \n",
       "1         9401      1  5202  46.000000      1.0     6.0      9.0   16   \n",
       "2         9001      1     0  61.611649      0.0     3.0      1.0    2   \n",
       "3         8701      0  2801  70.000000      0.0     1.0      4.0    2   \n",
       "4         8601      0  2001  78.000000      1.0     3.0      2.0   60   \n",
       "...        ...    ...   ...        ...      ...     ...      ...  ...   \n",
       "95407     9601      1     0  61.611649      0.0     5.0      5.0    0   \n",
       "95408     9601      1  5001  48.000000      1.0     7.0      9.0    1   \n",
       "95409     9501      1  3801  60.000000      0.0     5.0      5.0    0   \n",
       "95410     8601      0  4005  58.000000      0.0     7.0      5.0    0   \n",
       "95411     8801      2  1801  80.000000      0.0     5.0      8.0    3   \n",
       "\n",
       "       MBCRAFT  MBGARDEN  ...  STATE  CLUSTER  HOMEOWNR  GENDER  DATASRCE  \\\n",
       "0          0.0       0.0  ...     IL       36         N       F         0   \n",
       "1          0.0       0.0  ...     CA       14         H       M         3   \n",
       "2          0.0       0.0  ...     NC       43         U       M         3   \n",
       "3          0.0       0.0  ...     CA       44         U       F         3   \n",
       "4          1.0       0.0  ...     FL       16         H       F         3   \n",
       "...        ...       ...  ...    ...      ...       ...     ...       ...   \n",
       "95407      0.0       0.0  ...  other       27         N       M         0   \n",
       "95408      0.0       0.0  ...     TX       24         H       M         3   \n",
       "95409      0.0       0.0  ...     MI       30         N       M         0   \n",
       "95410      0.0       0.0  ...     CA       24         H       F         2   \n",
       "95411      0.0       0.0  ...     NC       24         U       F         3   \n",
       "\n",
       "       RFA_2R  RFA_2A  GEOCODE2  DOMAIN_A  DOMAIN_B  \n",
       "0           L       E         C         T         2  \n",
       "1           L       G         A         S         1  \n",
       "2           L       E         C         R         2  \n",
       "3           L       E         C         R         2  \n",
       "4           L       F         A         S         2  \n",
       "...       ...     ...       ...       ...       ...  \n",
       "95407       L       G         C         C         2  \n",
       "95408       L       F         A         C         1  \n",
       "95409       L       E         B         C         3  \n",
       "95410       L       F         A         C         1  \n",
       "95411       L       G         C         C         1  \n",
       "\n",
       "[95412 rows x 341 columns]"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ODATEDW</th>\n",
       "      <th>TCODE</th>\n",
       "      <th>DOB</th>\n",
       "      <th>AGE</th>\n",
       "      <th>NUMCHLD</th>\n",
       "      <th>INCOME</th>\n",
       "      <th>WEALTH1</th>\n",
       "      <th>HIT</th>\n",
       "      <th>MBCRAFT</th>\n",
       "      <th>MBGARDEN</th>\n",
       "      <th>...</th>\n",
       "      <th>STATE</th>\n",
       "      <th>CLUSTER</th>\n",
       "      <th>HOMEOWNR</th>\n",
       "      <th>GENDER</th>\n",
       "      <th>DATASRCE</th>\n",
       "      <th>RFA_2R</th>\n",
       "      <th>RFA_2A</th>\n",
       "      <th>GEOCODE2</th>\n",
       "      <th>DOMAIN_A</th>\n",
       "      <th>DOMAIN_B</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>85225</th>\n",
       "      <td>9601</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>61.611649</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>IL</td>\n",
       "      <td>2</td>\n",
       "      <td>N</td>\n",
       "      <td>F</td>\n",
       "      <td>0</td>\n",
       "      <td>L</td>\n",
       "      <td>F</td>\n",
       "      <td>A</td>\n",
       "      <td>U</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70004</th>\n",
       "      <td>9001</td>\n",
       "      <td>0</td>\n",
       "      <td>3401</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>TX</td>\n",
       "      <td>11</td>\n",
       "      <td>H</td>\n",
       "      <td>F</td>\n",
       "      <td>2</td>\n",
       "      <td>L</td>\n",
       "      <td>F</td>\n",
       "      <td>D</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88133</th>\n",
       "      <td>8801</td>\n",
       "      <td>1</td>\n",
       "      <td>3501</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>other</td>\n",
       "      <td>36</td>\n",
       "      <td>H</td>\n",
       "      <td>M</td>\n",
       "      <td>3</td>\n",
       "      <td>L</td>\n",
       "      <td>E</td>\n",
       "      <td>D</td>\n",
       "      <td>T</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79106</th>\n",
       "      <td>8801</td>\n",
       "      <td>2</td>\n",
       "      <td>2601</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>other</td>\n",
       "      <td>21</td>\n",
       "      <td>H</td>\n",
       "      <td>M</td>\n",
       "      <td>2</td>\n",
       "      <td>L</td>\n",
       "      <td>E</td>\n",
       "      <td>A</td>\n",
       "      <td>S</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35476</th>\n",
       "      <td>8901</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>61.611649</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>other</td>\n",
       "      <td>43</td>\n",
       "      <td>U</td>\n",
       "      <td>F</td>\n",
       "      <td>2</td>\n",
       "      <td>L</td>\n",
       "      <td>F</td>\n",
       "      <td>B</td>\n",
       "      <td>R</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6265</th>\n",
       "      <td>9509</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>61.611649</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>CA</td>\n",
       "      <td>23</td>\n",
       "      <td>H</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>L</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54886</th>\n",
       "      <td>9301</td>\n",
       "      <td>1</td>\n",
       "      <td>3601</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>IN</td>\n",
       "      <td>21</td>\n",
       "      <td>U</td>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "      <td>L</td>\n",
       "      <td>F</td>\n",
       "      <td>B</td>\n",
       "      <td>S</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76820</th>\n",
       "      <td>9101</td>\n",
       "      <td>0</td>\n",
       "      <td>5401</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NC</td>\n",
       "      <td>12</td>\n",
       "      <td>H</td>\n",
       "      <td>F</td>\n",
       "      <td>2</td>\n",
       "      <td>L</td>\n",
       "      <td>F</td>\n",
       "      <td>B</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>9401</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>61.611649</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>other</td>\n",
       "      <td>45</td>\n",
       "      <td>U</td>\n",
       "      <td>M</td>\n",
       "      <td>2</td>\n",
       "      <td>L</td>\n",
       "      <td>F</td>\n",
       "      <td>D</td>\n",
       "      <td>R</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15795</th>\n",
       "      <td>9201</td>\n",
       "      <td>0</td>\n",
       "      <td>4810</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>IL</td>\n",
       "      <td>22</td>\n",
       "      <td>H</td>\n",
       "      <td>F</td>\n",
       "      <td>2</td>\n",
       "      <td>L</td>\n",
       "      <td>E</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76329 rows × 341 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       ODATEDW  TCODE   DOB        AGE  NUMCHLD  INCOME  WEALTH1  HIT  \\\n",
       "85225     9601     28     0  61.611649      0.0     5.0      5.0    0   \n",
       "70004     9001      0  3401  64.000000      0.0     4.0      5.0    0   \n",
       "88133     8801      1  3501  63.000000      0.0     7.0      6.0    2   \n",
       "79106     8801      2  2601  72.000000      0.0     2.0      5.0    0   \n",
       "35476     8901      0     0  61.611649      0.0     1.0      5.0    0   \n",
       "...        ...    ...   ...        ...      ...     ...      ...  ...   \n",
       "6265      9509      0     0  61.611649      0.0     1.0      7.0    0   \n",
       "54886     9301      1  3601  62.000000      0.0     2.0      2.0    6   \n",
       "76820     9101      0  5401  44.000000      0.0     5.0      5.0    0   \n",
       "860       9401      0     0  61.611649      0.0     2.0      5.0    0   \n",
       "15795     9201      0  4810  49.000000      0.0     4.0      5.0    0   \n",
       "\n",
       "       MBCRAFT  MBGARDEN  ...  STATE  CLUSTER  HOMEOWNR  GENDER  DATASRCE  \\\n",
       "85225      0.0       0.0  ...     IL        2         N       F         0   \n",
       "70004      0.0       0.0  ...     TX       11         H       F         2   \n",
       "88133      0.0       0.0  ...  other       36         H       M         3   \n",
       "79106      0.0       0.0  ...  other       21         H       M         2   \n",
       "35476      0.0       0.0  ...  other       43         U       F         2   \n",
       "...        ...       ...  ...    ...      ...       ...     ...       ...   \n",
       "6265       1.0       0.0  ...     CA       23         H       F         1   \n",
       "54886      0.0       0.0  ...     IN       21         U       M         1   \n",
       "76820      0.0       0.0  ...     NC       12         H       F         2   \n",
       "860        0.0       0.0  ...  other       45         U       M         2   \n",
       "15795      0.0       0.0  ...     IL       22         H       F         2   \n",
       "\n",
       "       RFA_2R  RFA_2A  GEOCODE2  DOMAIN_A  DOMAIN_B  \n",
       "85225       L       F         A         U         1  \n",
       "70004       L       F         D         S         1  \n",
       "88133       L       E         D         T         2  \n",
       "79106       L       E         A         S         3  \n",
       "35476       L       F         B         R         2  \n",
       "...       ...     ...       ...       ...       ...  \n",
       "6265        L       G         A         C         1  \n",
       "54886       L       F         B         S         3  \n",
       "76820       L       F         B         S         1  \n",
       "860         L       F         D         R         2  \n",
       "15795       L       E         A         C         1  \n",
       "\n",
       "[76329 rows x 341 columns]"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ODATEDW</th>\n",
       "      <th>TCODE</th>\n",
       "      <th>DOB</th>\n",
       "      <th>AGE</th>\n",
       "      <th>NUMCHLD</th>\n",
       "      <th>INCOME</th>\n",
       "      <th>WEALTH1</th>\n",
       "      <th>HIT</th>\n",
       "      <th>MBCRAFT</th>\n",
       "      <th>MBGARDEN</th>\n",
       "      <th>...</th>\n",
       "      <th>STATE</th>\n",
       "      <th>CLUSTER</th>\n",
       "      <th>HOMEOWNR</th>\n",
       "      <th>GENDER</th>\n",
       "      <th>DATASRCE</th>\n",
       "      <th>RFA_2R</th>\n",
       "      <th>RFA_2A</th>\n",
       "      <th>GEOCODE2</th>\n",
       "      <th>DOMAIN_A</th>\n",
       "      <th>DOMAIN_B</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>84155</th>\n",
       "      <td>9601</td>\n",
       "      <td>1</td>\n",
       "      <td>5801</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>other</td>\n",
       "      <td>12</td>\n",
       "      <td>U</td>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "      <td>L</td>\n",
       "      <td>G</td>\n",
       "      <td>C</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75272</th>\n",
       "      <td>9101</td>\n",
       "      <td>0</td>\n",
       "      <td>2303</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>CA</td>\n",
       "      <td>19</td>\n",
       "      <td>N</td>\n",
       "      <td>U</td>\n",
       "      <td>0</td>\n",
       "      <td>L</td>\n",
       "      <td>E</td>\n",
       "      <td>A</td>\n",
       "      <td>S</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39719</th>\n",
       "      <td>9401</td>\n",
       "      <td>0</td>\n",
       "      <td>4601</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>MI</td>\n",
       "      <td>2</td>\n",
       "      <td>H</td>\n",
       "      <td>F</td>\n",
       "      <td>3</td>\n",
       "      <td>L</td>\n",
       "      <td>D</td>\n",
       "      <td>A</td>\n",
       "      <td>U</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44288</th>\n",
       "      <td>9301</td>\n",
       "      <td>0</td>\n",
       "      <td>4401</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>CA</td>\n",
       "      <td>12</td>\n",
       "      <td>H</td>\n",
       "      <td>F</td>\n",
       "      <td>2</td>\n",
       "      <td>L</td>\n",
       "      <td>F</td>\n",
       "      <td>A</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35420</th>\n",
       "      <td>9101</td>\n",
       "      <td>1</td>\n",
       "      <td>4201</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>other</td>\n",
       "      <td>26</td>\n",
       "      <td>H</td>\n",
       "      <td>M</td>\n",
       "      <td>3</td>\n",
       "      <td>L</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38584</th>\n",
       "      <td>9401</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>61.611649</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>other</td>\n",
       "      <td>43</td>\n",
       "      <td>N</td>\n",
       "      <td>F</td>\n",
       "      <td>0</td>\n",
       "      <td>L</td>\n",
       "      <td>F</td>\n",
       "      <td>C</td>\n",
       "      <td>R</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54025</th>\n",
       "      <td>9401</td>\n",
       "      <td>1</td>\n",
       "      <td>3201</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>TX</td>\n",
       "      <td>21</td>\n",
       "      <td>H</td>\n",
       "      <td>M</td>\n",
       "      <td>2</td>\n",
       "      <td>L</td>\n",
       "      <td>F</td>\n",
       "      <td>A</td>\n",
       "      <td>S</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76819</th>\n",
       "      <td>9401</td>\n",
       "      <td>0</td>\n",
       "      <td>4701</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>other</td>\n",
       "      <td>13</td>\n",
       "      <td>H</td>\n",
       "      <td>M</td>\n",
       "      <td>3</td>\n",
       "      <td>L</td>\n",
       "      <td>F</td>\n",
       "      <td>B</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2549</th>\n",
       "      <td>9601</td>\n",
       "      <td>0</td>\n",
       "      <td>5901</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>other</td>\n",
       "      <td>10</td>\n",
       "      <td>H</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>L</td>\n",
       "      <td>F</td>\n",
       "      <td>B</td>\n",
       "      <td>U</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63732</th>\n",
       "      <td>8601</td>\n",
       "      <td>2</td>\n",
       "      <td>3305</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>other</td>\n",
       "      <td>27</td>\n",
       "      <td>H</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>L</td>\n",
       "      <td>G</td>\n",
       "      <td>D</td>\n",
       "      <td>C</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19083 rows × 341 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       ODATEDW  TCODE   DOB        AGE  NUMCHLD  INCOME  WEALTH1  HIT  \\\n",
       "84155     9601      1  5801  40.000000      0.0     6.0      9.0   11   \n",
       "75272     9101      0  2303  75.000000      0.0     5.0      5.0    0   \n",
       "39719     9401      0  4601  52.000000      0.0     7.0      9.0    8   \n",
       "44288     9301      0  4401  54.000000      1.0     7.0      5.0    0   \n",
       "35420     9101      1  4201  56.000000      0.0     5.0      6.0    2   \n",
       "...        ...    ...   ...        ...      ...     ...      ...  ...   \n",
       "38584     9401      2     0  61.611649      0.0     5.0      5.0    0   \n",
       "54025     9401      1  3201  66.000000      0.0     5.0      5.0    0   \n",
       "76819     9401      0  4701  51.000000      0.0     6.0      9.0    0   \n",
       "2549      9601      0  5901  39.000000      0.0     4.0      3.0    1   \n",
       "63732     8601      2  3305  65.000000      0.0     3.0      8.0    1   \n",
       "\n",
       "       MBCRAFT  MBGARDEN  ...  STATE  CLUSTER  HOMEOWNR  GENDER  DATASRCE  \\\n",
       "84155      0.0       0.0  ...  other       12         U       M         1   \n",
       "75272      0.0       0.0  ...     CA       19         N       U         0   \n",
       "39719      0.0       0.0  ...     MI        2         H       F         3   \n",
       "44288      0.0       0.0  ...     CA       12         H       F         2   \n",
       "35420      0.0       0.0  ...  other       26         H       M         3   \n",
       "...        ...       ...  ...    ...      ...       ...     ...       ...   \n",
       "38584      0.0       0.0  ...  other       43         N       F         0   \n",
       "54025      0.0       0.0  ...     TX       21         H       M         2   \n",
       "76819      0.0       0.0  ...  other       13         H       M         3   \n",
       "2549       0.0       0.0  ...  other       10         H       F         1   \n",
       "63732      0.0       0.0  ...  other       27         H       F         1   \n",
       "\n",
       "       RFA_2R  RFA_2A  GEOCODE2  DOMAIN_A  DOMAIN_B  \n",
       "84155       L       G         C         S         1  \n",
       "75272       L       E         A         S         2  \n",
       "39719       L       D         A         U         1  \n",
       "44288       L       F         A         S         1  \n",
       "35420       L       G         A         C         2  \n",
       "...       ...     ...       ...       ...       ...  \n",
       "38584       L       F         C         R         2  \n",
       "54025       L       F         A         S         3  \n",
       "76819       L       F         B         S         1  \n",
       "2549        L       F         B         U         4  \n",
       "63732       L       G         D         C         2  \n",
       "\n",
       "[19083 rows x 341 columns]"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numerical train test split\n",
    "numericals_train = X_train.select_dtypes(np.number)\n",
    "numericals_test = X_test.select_dtypes(np.number)\n",
    "\n",
    "# categorical train test split\n",
    "categoricals_train= X_train.select_dtypes(object)\n",
    "categoricals_test= X_test.select_dtypes(object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ODATEDW', 'TCODE', 'DOB', 'AGE', 'NUMCHLD', 'INCOME', 'WEALTH1', 'HIT',\n",
       "       'MBCRAFT', 'MBGARDEN',\n",
       "       ...\n",
       "       'FISTDATE', 'TIMELAG', 'AVGGIFT', 'CONTROLN', 'HPHONE_D', 'RFA_2F',\n",
       "       'CLUSTER2', 'CLUSTER', 'DATASRCE', 'DOMAIN_B'],\n",
       "      dtype='object', length=334)"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numericals_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling numerical values using Min-Max Scaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Instantiate MinMaxScaler and fit it to the training data\n",
    "transformer = MinMaxScaler().fit(numericals_train)\n",
    "\n",
    "# Transform the training and test numerical data using the fitted scaler\n",
    "numericals_train_scaled = pd.DataFrame(transformer.transform(numericals_train), columns=numericals_train.columns).reset_index(drop=True)\n",
    "numericals_test_scaled = pd.DataFrame(transformer.transform(numericals_test), columns=numericals_test.columns).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Assuming 'categoricals_train' is the DataFrame used to fit the encoder\n",
    "# fit the encoder using the train data\n",
    "encoder = OneHotEncoder(handle_unknown='error').fit(categoricals_train)\n",
    "\n",
    "# Get the original column names for both the test and train data\n",
    "cols_train = encoder.get_feature_names_out(input_features=categoricals_train.columns)\n",
    "cols_test = encoder.get_feature_names_out(input_features=categoricals_test.columns)\n",
    "\n",
    "# Replace the generated feature names with the original column names\n",
    "categoricals_train_encoded = pd.DataFrame(encoder.transform(categoricals_train).toarray(), columns=cols_train)\n",
    "categoricals_test_encoded = pd.DataFrame(encoder.transform(categoricals_test).toarray(), columns=cols_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concat numerical an categoricals into separate tables for test and train samples\n",
    "X_train=pd.concat([numericals_train_scaled ,categoricals_train_encoded], axis=1)\n",
    "X_test=pd.concat([numericals_test_scaled ,categoricals_test_encoded], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.reset_index(drop=True)\n",
    "y_test = y_test.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ODATEDW</th>\n",
       "      <th>TCODE</th>\n",
       "      <th>DOB</th>\n",
       "      <th>AGE</th>\n",
       "      <th>NUMCHLD</th>\n",
       "      <th>INCOME</th>\n",
       "      <th>WEALTH1</th>\n",
       "      <th>HIT</th>\n",
       "      <th>MBCRAFT</th>\n",
       "      <th>MBGARDEN</th>\n",
       "      <th>...</th>\n",
       "      <th>RFA_2A_G</th>\n",
       "      <th>GEOCODE2_A</th>\n",
       "      <th>GEOCODE2_B</th>\n",
       "      <th>GEOCODE2_C</th>\n",
       "      <th>GEOCODE2_D</th>\n",
       "      <th>DOMAIN_A_C</th>\n",
       "      <th>DOMAIN_A_R</th>\n",
       "      <th>DOMAIN_A_S</th>\n",
       "      <th>DOMAIN_A_T</th>\n",
       "      <th>DOMAIN_A_U</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.928315</td>\n",
       "      <td>0.000389</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.624862</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.498208</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.350257</td>\n",
       "      <td>0.649485</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.354839</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.360556</td>\n",
       "      <td>0.639175</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.008299</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.354839</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>0.267868</td>\n",
       "      <td>0.731959</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.426523</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.624862</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76324</th>\n",
       "      <td>0.862366</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.624862</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76325</th>\n",
       "      <td>0.713262</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.370855</td>\n",
       "      <td>0.628866</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.024896</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76326</th>\n",
       "      <td>0.569892</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.556231</td>\n",
       "      <td>0.443299</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76327</th>\n",
       "      <td>0.784946</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.624862</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76328</th>\n",
       "      <td>0.641577</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.495366</td>\n",
       "      <td>0.494845</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76329 rows × 366 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ODATEDW     TCODE       DOB       AGE  NUMCHLD    INCOME   WEALTH1  \\\n",
       "0      0.928315  0.000389  0.000000  0.624862      0.0  0.666667  0.555556   \n",
       "1      0.498208  0.000000  0.350257  0.649485      0.0  0.500000  0.555556   \n",
       "2      0.354839  0.000014  0.360556  0.639175      0.0  1.000000  0.666667   \n",
       "3      0.354839  0.000028  0.267868  0.731959      0.0  0.166667  0.555556   \n",
       "4      0.426523  0.000000  0.000000  0.624862      0.0  0.000000  0.555556   \n",
       "...         ...       ...       ...       ...      ...       ...       ...   \n",
       "76324  0.862366  0.000000  0.000000  0.624862      0.0  0.000000  0.777778   \n",
       "76325  0.713262  0.000014  0.370855  0.628866      0.0  0.166667  0.222222   \n",
       "76326  0.569892  0.000000  0.556231  0.443299      0.0  0.666667  0.555556   \n",
       "76327  0.784946  0.000000  0.000000  0.624862      0.0  0.166667  0.555556   \n",
       "76328  0.641577  0.000000  0.495366  0.494845      0.0  0.500000  0.555556   \n",
       "\n",
       "            HIT  MBCRAFT  MBGARDEN  ...  RFA_2A_G  GEOCODE2_A  GEOCODE2_B  \\\n",
       "0      0.000000      0.0       0.0  ...       0.0         1.0         0.0   \n",
       "1      0.000000      0.0       0.0  ...       0.0         0.0         0.0   \n",
       "2      0.008299      0.0       0.0  ...       0.0         0.0         0.0   \n",
       "3      0.000000      0.0       0.0  ...       0.0         1.0         0.0   \n",
       "4      0.000000      0.0       0.0  ...       0.0         0.0         1.0   \n",
       "...         ...      ...       ...  ...       ...         ...         ...   \n",
       "76324  0.000000      0.2       0.0  ...       1.0         1.0         0.0   \n",
       "76325  0.024896      0.0       0.0  ...       0.0         0.0         1.0   \n",
       "76326  0.000000      0.0       0.0  ...       0.0         0.0         1.0   \n",
       "76327  0.000000      0.0       0.0  ...       0.0         0.0         0.0   \n",
       "76328  0.000000      0.0       0.0  ...       0.0         1.0         0.0   \n",
       "\n",
       "       GEOCODE2_C  GEOCODE2_D  DOMAIN_A_C  DOMAIN_A_R  DOMAIN_A_S  DOMAIN_A_T  \\\n",
       "0             0.0         0.0         0.0         0.0         0.0         0.0   \n",
       "1             0.0         1.0         0.0         0.0         1.0         0.0   \n",
       "2             0.0         1.0         0.0         0.0         0.0         1.0   \n",
       "3             0.0         0.0         0.0         0.0         1.0         0.0   \n",
       "4             0.0         0.0         0.0         1.0         0.0         0.0   \n",
       "...           ...         ...         ...         ...         ...         ...   \n",
       "76324         0.0         0.0         1.0         0.0         0.0         0.0   \n",
       "76325         0.0         0.0         0.0         0.0         1.0         0.0   \n",
       "76326         0.0         0.0         0.0         0.0         1.0         0.0   \n",
       "76327         0.0         1.0         0.0         1.0         0.0         0.0   \n",
       "76328         0.0         0.0         1.0         0.0         0.0         0.0   \n",
       "\n",
       "       DOMAIN_A_U  \n",
       "0             1.0  \n",
       "1             0.0  \n",
       "2             0.0  \n",
       "3             0.0  \n",
       "4             0.0  \n",
       "...           ...  \n",
       "76324         0.0  \n",
       "76325         0.0  \n",
       "76326         0.0  \n",
       "76327         0.0  \n",
       "76328         0.0  \n",
       "\n",
       "[76329 rows x 366 columns]"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# donor prediction model without oversampling or feture selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9487501965099827\n",
      "precision:  0.0\n",
      "recall:  0.0\n",
      "f1:  0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\usuario\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Reshape the target variable to ensure it is in the correct format\n",
    "y_train_reshaped = np.ravel(y_train)\n",
    "\n",
    "# Train a logistic regression classifier using the training data\n",
    "LR = LogisticRegression(random_state=42, solver='lbfgs', max_iter=4000).fit(X_train, y_train_reshaped)\n",
    "\n",
    "# Predict using the trained model on the test set\n",
    "pred = LR.predict(X_test)\n",
    "\n",
    "# Print evaluation metrics\n",
    "print('accuracy:', accuracy_score(y_test, pred))  # Print accuracy\n",
    "print(\"precision: \",precision_score(y_test,pred))  # Print precision\n",
    "print(\"recall: \",recall_score(y_test,pred))  # Print recall\n",
    "print(\"f1: \",f1_score(y_test,pred))  # Print F1 score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Compute confusion matrix\n",
    "cm = confusion_matrix(y_test, pred)\n",
    "\n",
    "# Create a ConfusionMatrixDisplay object with the computed confusion matrix\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "\n",
    "# Plot the confusion matrix\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While our model has an impressive accuracy score of nearly 95%, however it is crucial to recognize that it failed to identify any donors, as ahown by a 0 recall core. This deficiency underscores a pronounced bias within the dataset, primarily due to a substantial imbalance between the number of donor and non-donor samples. The precision score, indicating the accuracy of our positive predictions, registered at 0%, indicating a complete inability to correctly identify potential donors. Rectifying this imbalance is paramount to enhancing the precision and overall reliability of our model's predictions. To address this issue, we must ensure a more equitable distribution of donor and non-donor samples during model training. By achieving this balance, our model can learn from both groups effectively, resulting in more accurate and dependable predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With 366 columns in the dataframe, there's ample opportunity to enhance the computational efficiency of the model. By selectively removing columns with the lowest correlation, we can streamline the dataset and potentially reduce computational overhead significantly. This approach not only optimizes processing speed but also has the potential to improve the precision of our predictions by eliminating redundant information. By focusing on the most correlated features, we can ensure that the model prioritizes the most relevant aspects of the data when predicting donor behavior. Ultimately, this targeted feature selection strategy can lead to more efficient and accurate predictions, enhancing the overall performance of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This process will only be done with the numerical data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ODATEDW</th>\n",
       "      <th>TCODE</th>\n",
       "      <th>DOB</th>\n",
       "      <th>AGE</th>\n",
       "      <th>NUMCHLD</th>\n",
       "      <th>INCOME</th>\n",
       "      <th>WEALTH1</th>\n",
       "      <th>HIT</th>\n",
       "      <th>MBCRAFT</th>\n",
       "      <th>MBGARDEN</th>\n",
       "      <th>...</th>\n",
       "      <th>FISTDATE</th>\n",
       "      <th>TIMELAG</th>\n",
       "      <th>AVGGIFT</th>\n",
       "      <th>CONTROLN</th>\n",
       "      <th>HPHONE_D</th>\n",
       "      <th>RFA_2F</th>\n",
       "      <th>CLUSTER2</th>\n",
       "      <th>CLUSTER</th>\n",
       "      <th>DATASRCE</th>\n",
       "      <th>DOMAIN_B</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.928315</td>\n",
       "      <td>0.000389</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.624862</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999896</td>\n",
       "      <td>0.008272</td>\n",
       "      <td>0.013732</td>\n",
       "      <td>0.472526</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.426230</td>\n",
       "      <td>0.019231</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.498208</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.350257</td>\n",
       "      <td>0.649485</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.938248</td>\n",
       "      <td>0.000919</td>\n",
       "      <td>0.013277</td>\n",
       "      <td>0.098807</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.950820</td>\n",
       "      <td>0.192308</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.354839</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.360556</td>\n",
       "      <td>0.639175</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.008299</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.917318</td>\n",
       "      <td>0.012868</td>\n",
       "      <td>0.004407</td>\n",
       "      <td>0.307856</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.852459</td>\n",
       "      <td>0.673077</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.354839</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>0.267868</td>\n",
       "      <td>0.731959</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.917213</td>\n",
       "      <td>0.020221</td>\n",
       "      <td>0.005610</td>\n",
       "      <td>0.429001</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.344262</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.426523</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.624862</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.927835</td>\n",
       "      <td>0.005515</td>\n",
       "      <td>0.010585</td>\n",
       "      <td>0.733875</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.688525</td>\n",
       "      <td>0.807692</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76324</th>\n",
       "      <td>0.862366</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.624862</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.990211</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.023745</td>\n",
       "      <td>0.865417</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.180328</td>\n",
       "      <td>0.423077</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76325</th>\n",
       "      <td>0.713262</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.370855</td>\n",
       "      <td>0.628866</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.024896</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.968551</td>\n",
       "      <td>0.002757</td>\n",
       "      <td>0.011229</td>\n",
       "      <td>0.314400</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.360656</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76326</th>\n",
       "      <td>0.569892</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.556231</td>\n",
       "      <td>0.443299</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.948245</td>\n",
       "      <td>0.009191</td>\n",
       "      <td>0.010311</td>\n",
       "      <td>0.087414</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.311475</td>\n",
       "      <td>0.211538</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76327</th>\n",
       "      <td>0.784946</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.624862</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.979069</td>\n",
       "      <td>0.011949</td>\n",
       "      <td>0.007724</td>\n",
       "      <td>0.549046</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.950820</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76328</th>\n",
       "      <td>0.641577</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.495366</td>\n",
       "      <td>0.494845</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.958242</td>\n",
       "      <td>0.001838</td>\n",
       "      <td>0.006075</td>\n",
       "      <td>0.044202</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.114754</td>\n",
       "      <td>0.403846</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76329 rows × 334 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ODATEDW     TCODE       DOB       AGE  NUMCHLD    INCOME   WEALTH1  \\\n",
       "0      0.928315  0.000389  0.000000  0.624862      0.0  0.666667  0.555556   \n",
       "1      0.498208  0.000000  0.350257  0.649485      0.0  0.500000  0.555556   \n",
       "2      0.354839  0.000014  0.360556  0.639175      0.0  1.000000  0.666667   \n",
       "3      0.354839  0.000028  0.267868  0.731959      0.0  0.166667  0.555556   \n",
       "4      0.426523  0.000000  0.000000  0.624862      0.0  0.000000  0.555556   \n",
       "...         ...       ...       ...       ...      ...       ...       ...   \n",
       "76324  0.862366  0.000000  0.000000  0.624862      0.0  0.000000  0.777778   \n",
       "76325  0.713262  0.000014  0.370855  0.628866      0.0  0.166667  0.222222   \n",
       "76326  0.569892  0.000000  0.556231  0.443299      0.0  0.666667  0.555556   \n",
       "76327  0.784946  0.000000  0.000000  0.624862      0.0  0.166667  0.555556   \n",
       "76328  0.641577  0.000000  0.495366  0.494845      0.0  0.500000  0.555556   \n",
       "\n",
       "            HIT  MBCRAFT  MBGARDEN  ...  FISTDATE   TIMELAG   AVGGIFT  \\\n",
       "0      0.000000      0.0       0.0  ...  0.999896  0.008272  0.013732   \n",
       "1      0.000000      0.0       0.0  ...  0.938248  0.000919  0.013277   \n",
       "2      0.008299      0.0       0.0  ...  0.917318  0.012868  0.004407   \n",
       "3      0.000000      0.0       0.0  ...  0.917213  0.020221  0.005610   \n",
       "4      0.000000      0.0       0.0  ...  0.927835  0.005515  0.010585   \n",
       "...         ...      ...       ...  ...       ...       ...       ...   \n",
       "76324  0.000000      0.2       0.0  ...  0.990211  0.000000  0.023745   \n",
       "76325  0.024896      0.0       0.0  ...  0.968551  0.002757  0.011229   \n",
       "76326  0.000000      0.0       0.0  ...  0.948245  0.009191  0.010311   \n",
       "76327  0.000000      0.0       0.0  ...  0.979069  0.011949  0.007724   \n",
       "76328  0.000000      0.0       0.0  ...  0.958242  0.001838  0.006075   \n",
       "\n",
       "       CONTROLN  HPHONE_D    RFA_2F  CLUSTER2   CLUSTER  DATASRCE  DOMAIN_B  \n",
       "0      0.472526       1.0  0.000000  0.426230  0.019231  0.000000  0.000000  \n",
       "1      0.098807       0.0  0.333333  0.950820  0.192308  0.666667  0.000000  \n",
       "2      0.307856       1.0  0.333333  0.852459  0.673077  1.000000  0.333333  \n",
       "3      0.429001       1.0  0.000000  0.344262  0.384615  0.666667  0.666667  \n",
       "4      0.733875       1.0  0.000000  0.688525  0.807692  0.666667  0.333333  \n",
       "...         ...       ...       ...       ...       ...       ...       ...  \n",
       "76324  0.865417       0.0  0.000000  0.180328  0.423077  0.333333  0.000000  \n",
       "76325  0.314400       0.0  0.333333  0.360656  0.384615  0.333333  0.666667  \n",
       "76326  0.087414       0.0  0.333333  0.311475  0.211538  0.666667  0.000000  \n",
       "76327  0.549046       1.0  0.000000  0.950820  0.846154  0.666667  0.333333  \n",
       "76328  0.044202       1.0  1.000000  0.114754  0.403846  0.666667  0.000000  \n",
       "\n",
       "[76329 rows x 334 columns]"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numericals_train_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(76329, 334)\n",
      "(76329, 85)\n"
     ]
    }
   ],
   "source": [
    "# Using the variance threshold for feature selection\n",
    "\n",
    "# Import the VarianceThreshold class from the feature_selection module\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "# Set the variance threshold value\n",
    "Var_threshold = 0.02\n",
    "\n",
    "# Instantiate the VarianceThreshold object with the specified threshold value\n",
    "sel = VarianceThreshold(threshold=Var_threshold)\n",
    "\n",
    "# Fit the VarianceThreshold object to the scaled numerical training data\n",
    "sel = sel.fit(numericals_train_scaled)\n",
    "\n",
    "# Transform the scaled numerical training data using the fitted VarianceThreshold object\n",
    "temp = sel.transform(numericals_train_scaled)\n",
    "\n",
    "# Convert the transformed data into a DataFrame\n",
    "temp = pd.DataFrame(temp)\n",
    "\n",
    "# Print the shapes of the original and transformed dataframes\n",
    "print(numericals_train_scaled.shape)  # Print the shape of the original dataframe\n",
    "print(temp.shape)  # Print the shape of the transformed dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "334\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('ODATEDW', True),\n",
       " ('TCODE', False),\n",
       " ('DOB', True),\n",
       " ('AGE', True),\n",
       " ('NUMCHLD', False),\n",
       " ('INCOME', True),\n",
       " ('WEALTH1', True),\n",
       " ('HIT', False),\n",
       " ('MBCRAFT', False),\n",
       " ('MBGARDEN', False),\n",
       " ('MBBOOKS', False),\n",
       " ('MBCOLECT', False),\n",
       " ('MAGFAML', False),\n",
       " ('MAGFEM', False),\n",
       " ('MAGMALE', False),\n",
       " ('PUBGARDN', False),\n",
       " ('PUBCULIN', False),\n",
       " ('PUBHLTH', False),\n",
       " ('PUBDOITY', False),\n",
       " ('PUBNEWFN', False),\n",
       " ('PUBPHOTO', False),\n",
       " ('PUBOPP', False),\n",
       " ('MALEMILI', False),\n",
       " ('MALEVET', True),\n",
       " ('VIETVETS', True),\n",
       " ('WWIIVETS', True),\n",
       " ('LOCALGOV', False),\n",
       " ('STATEGOV', False),\n",
       " ('FEDGOV', False),\n",
       " ('WEALTH2', True),\n",
       " ('POP901', False),\n",
       " ('POP902', False),\n",
       " ('POP903', False),\n",
       " ('POP90C1', True),\n",
       " ('POP90C2', True),\n",
       " ('POP90C3', True),\n",
       " ('POP90C4', False),\n",
       " ('POP90C5', False),\n",
       " ('ETH1', True),\n",
       " ('ETH2', True),\n",
       " ('ETH3', False),\n",
       " ('ETH4', False),\n",
       " ('ETH5', False),\n",
       " ('ETH6', False),\n",
       " ('ETH7', False),\n",
       " ('ETH8', False),\n",
       " ('ETH9', False),\n",
       " ('ETH10', False),\n",
       " ('ETH11', False),\n",
       " ('ETH12', False),\n",
       " ('ETH13', False),\n",
       " ('ETH14', False),\n",
       " ('ETH15', False),\n",
       " ('ETH16', False),\n",
       " ('AGE901', False),\n",
       " ('AGE902', False),\n",
       " ('AGE903', False),\n",
       " ('AGE904', False),\n",
       " ('AGE905', False),\n",
       " ('AGE906', False),\n",
       " ('AGE907', False),\n",
       " ('CHIL1', False),\n",
       " ('CHIL2', False),\n",
       " ('CHIL3', False),\n",
       " ('AGEC1', False),\n",
       " ('AGEC2', False),\n",
       " ('AGEC3', False),\n",
       " ('AGEC4', False),\n",
       " ('AGEC5', False),\n",
       " ('AGEC6', False),\n",
       " ('AGEC7', False),\n",
       " ('CHILC1', False),\n",
       " ('CHILC2', False),\n",
       " ('CHILC3', False),\n",
       " ('CHILC4', False),\n",
       " ('CHILC5', False),\n",
       " ('HHAGE1', False),\n",
       " ('HHAGE2', False),\n",
       " ('HHAGE3', False),\n",
       " ('HHN1', False),\n",
       " ('HHN2', False),\n",
       " ('HHN3', True),\n",
       " ('HHN4', False),\n",
       " ('HHN5', False),\n",
       " ('HHN6', False),\n",
       " ('MARR1', False),\n",
       " ('MARR2', False),\n",
       " ('MARR3', False),\n",
       " ('MARR4', False),\n",
       " ('HHP1', False),\n",
       " ('HHP2', False),\n",
       " ('DW1', True),\n",
       " ('DW2', True),\n",
       " ('DW3', False),\n",
       " ('DW4', True),\n",
       " ('DW5', True),\n",
       " ('DW6', True),\n",
       " ('DW7', False),\n",
       " ('DW8', False),\n",
       " ('DW9', False),\n",
       " ('HV1', True),\n",
       " ('HV2', True),\n",
       " ('HV3', True),\n",
       " ('HV4', True),\n",
       " ('HU1', True),\n",
       " ('HU2', True),\n",
       " ('HU3', False),\n",
       " ('HU4', False),\n",
       " ('HU5', True),\n",
       " ('HHD1', False),\n",
       " ('HHD2', True),\n",
       " ('HHD3', True),\n",
       " ('HHD4', False),\n",
       " ('HHD5', False),\n",
       " ('HHD6', False),\n",
       " ('HHD7', False),\n",
       " ('HHD8', False),\n",
       " ('HHD9', False),\n",
       " ('HHD10', False),\n",
       " ('HHD11', False),\n",
       " ('HHD12', False),\n",
       " ('ETHC1', False),\n",
       " ('ETHC2', False),\n",
       " ('ETHC3', False),\n",
       " ('ETHC4', False),\n",
       " ('ETHC5', False),\n",
       " ('ETHC6', False),\n",
       " ('HVP1', True),\n",
       " ('HVP2', True),\n",
       " ('HVP3', True),\n",
       " ('HVP4', True),\n",
       " ('HVP5', True),\n",
       " ('HVP6', True),\n",
       " ('HUR1', False),\n",
       " ('HUR2', True),\n",
       " ('RHP1', False),\n",
       " ('RHP2', False),\n",
       " ('RHP3', False),\n",
       " ('RHP4', False),\n",
       " ('HUPA1', False),\n",
       " ('HUPA2', True),\n",
       " ('HUPA3', True),\n",
       " ('HUPA4', False),\n",
       " ('HUPA5', False),\n",
       " ('HUPA6', True),\n",
       " ('HUPA7', False),\n",
       " ('RP1', True),\n",
       " ('RP2', True),\n",
       " ('RP3', True),\n",
       " ('RP4', True),\n",
       " ('MSA', True),\n",
       " ('ADI', True),\n",
       " ('DMA', False),\n",
       " ('IC1', False),\n",
       " ('IC2', False),\n",
       " ('IC3', False),\n",
       " ('IC4', False),\n",
       " ('IC5', False),\n",
       " ('IC6', True),\n",
       " ('IC7', True),\n",
       " ('IC8', False),\n",
       " ('IC9', False),\n",
       " ('IC10', False),\n",
       " ('IC11', False),\n",
       " ('IC12', False),\n",
       " ('IC13', False),\n",
       " ('IC14', False),\n",
       " ('IC15', False),\n",
       " ('IC16', False),\n",
       " ('IC17', False),\n",
       " ('IC18', False),\n",
       " ('IC19', False),\n",
       " ('IC20', True),\n",
       " ('IC21', False),\n",
       " ('IC22', False),\n",
       " ('IC23', False),\n",
       " ('HHAS1', True),\n",
       " ('HHAS2', False),\n",
       " ('HHAS3', True),\n",
       " ('HHAS4', False),\n",
       " ('MC1', True),\n",
       " ('MC2', True),\n",
       " ('MC3', False),\n",
       " ('TPE1', False),\n",
       " ('TPE2', False),\n",
       " ('TPE3', False),\n",
       " ('TPE4', False),\n",
       " ('TPE5', False),\n",
       " ('TPE6', False),\n",
       " ('TPE7', False),\n",
       " ('TPE8', False),\n",
       " ('TPE9', False),\n",
       " ('PEC1', False),\n",
       " ('PEC2', True),\n",
       " ('TPE10', False),\n",
       " ('TPE11', False),\n",
       " ('TPE12', False),\n",
       " ('TPE13', True),\n",
       " ('LFC1', False),\n",
       " ('LFC2', True),\n",
       " ('LFC3', False),\n",
       " ('LFC4', True),\n",
       " ('LFC5', False),\n",
       " ('LFC6', True),\n",
       " ('LFC7', True),\n",
       " ('LFC8', True),\n",
       " ('LFC9', True),\n",
       " ('LFC10', False),\n",
       " ('OCC1', False),\n",
       " ('OCC2', False),\n",
       " ('OCC3', False),\n",
       " ('OCC4', False),\n",
       " ('OCC5', False),\n",
       " ('OCC6', False),\n",
       " ('OCC7', False),\n",
       " ('OCC8', False),\n",
       " ('OCC9', False),\n",
       " ('OCC10', False),\n",
       " ('OCC11', False),\n",
       " ('OCC12', False),\n",
       " ('OCC13', False),\n",
       " ('EIC1', False),\n",
       " ('EIC2', False),\n",
       " ('EIC3', False),\n",
       " ('EIC4', True),\n",
       " ('EIC5', False),\n",
       " ('EIC6', False),\n",
       " ('EIC7', False),\n",
       " ('EIC8', False),\n",
       " ('EIC9', False),\n",
       " ('EIC10', False),\n",
       " ('EIC11', False),\n",
       " ('EIC12', False),\n",
       " ('EIC13', False),\n",
       " ('EIC14', False),\n",
       " ('EIC15', False),\n",
       " ('EIC16', False),\n",
       " ('OEDC1', False),\n",
       " ('OEDC2', False),\n",
       " ('OEDC3', False),\n",
       " ('OEDC4', False),\n",
       " ('OEDC5', False),\n",
       " ('OEDC6', False),\n",
       " ('OEDC7', False),\n",
       " ('EC1', False),\n",
       " ('EC2', False),\n",
       " ('EC3', False),\n",
       " ('EC4', True),\n",
       " ('EC5', True),\n",
       " ('EC6', False),\n",
       " ('EC7', True),\n",
       " ('EC8', False),\n",
       " ('SEC1', False),\n",
       " ('SEC2', False),\n",
       " ('SEC3', False),\n",
       " ('SEC4', True),\n",
       " ('SEC5', False),\n",
       " ('AFC1', False),\n",
       " ('AFC2', False),\n",
       " ('AFC3', False),\n",
       " ('AFC4', False),\n",
       " ('AFC5', False),\n",
       " ('AFC6', False),\n",
       " ('VC1', True),\n",
       " ('VC2', False),\n",
       " ('VC3', True),\n",
       " ('VC4', False),\n",
       " ('ANC1', False),\n",
       " ('ANC2', False),\n",
       " ('ANC3', False),\n",
       " ('ANC4', False),\n",
       " ('ANC5', False),\n",
       " ('ANC6', False),\n",
       " ('ANC7', False),\n",
       " ('ANC8', False),\n",
       " ('ANC9', False),\n",
       " ('ANC10', False),\n",
       " ('ANC11', False),\n",
       " ('ANC12', False),\n",
       " ('ANC13', False),\n",
       " ('ANC14', False),\n",
       " ('ANC15', False),\n",
       " ('POBC1', False),\n",
       " ('POBC2', True),\n",
       " ('LSC1', True),\n",
       " ('LSC2', False),\n",
       " ('LSC3', False),\n",
       " ('LSC4', False),\n",
       " ('VOC1', False),\n",
       " ('VOC2', True),\n",
       " ('VOC3', True),\n",
       " ('HC1', False),\n",
       " ('HC2', True),\n",
       " ('HC3', False),\n",
       " ('HC4', True),\n",
       " ('HC5', True),\n",
       " ('HC6', True),\n",
       " ('HC7', True),\n",
       " ('HC8', True),\n",
       " ('HC9', False),\n",
       " ('HC10', False),\n",
       " ('HC11', True),\n",
       " ('HC12', True),\n",
       " ('HC13', True),\n",
       " ('HC14', False),\n",
       " ('HC15', False),\n",
       " ('HC16', False),\n",
       " ('HC17', True),\n",
       " ('HC18', True),\n",
       " ('HC19', True),\n",
       " ('HC20', False),\n",
       " ('HC21', False),\n",
       " ('MHUC1', True),\n",
       " ('MHUC2', True),\n",
       " ('AC1', False),\n",
       " ('AC2', False),\n",
       " ('CARDPROM', True),\n",
       " ('NUMPROM', False),\n",
       " ('CARDPM12', False),\n",
       " ('NUMPRM12', False),\n",
       " ('NGIFTALL', False),\n",
       " ('CARDGIFT', False),\n",
       " ('LASTGIFT', False),\n",
       " ('LASTDATE', True),\n",
       " ('FISTDATE', True),\n",
       " ('TIMELAG', False),\n",
       " ('AVGGIFT', False),\n",
       " ('CONTROLN', True),\n",
       " ('HPHONE_D', True),\n",
       " ('RFA_2F', True),\n",
       " ('CLUSTER2', True),\n",
       " ('CLUSTER', True),\n",
       " ('DATASRCE', True),\n",
       " ('DOMAIN_B', True)]"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if the variances of the selected features are greater than the variance threshold\n",
    "\n",
    "# Compute a boolean array indicating whether the variances of the selected features exceed the variance threshold\n",
    "variances_above_threshold = sel.variances_ > Var_threshold\n",
    "\n",
    "# Retrieve the support mask indicating which features are selected\n",
    "\n",
    "# Retrieve the binary mask indicating which features are selected by the feature selector\n",
    "support_mask = sel.get_support()\n",
    "\n",
    "# Convert the support mask to a list\n",
    "\n",
    "# Convert the binary support mask into a list of boolean values indicating feature selection status\n",
    "var_list = list(support_mask)\n",
    "\n",
    "# Calculate the length of the list\n",
    "\n",
    "# Calculate the number of selected features by determining the length of the support mask list\n",
    "selected_features_count = len(var_list)\n",
    "\n",
    "# Calculate the number of columns in the DataFrame 'numericals_train_scaled'\n",
    "\n",
    "# Count the number of columns in the DataFrame 'numericals_train_scaled'\n",
    "numerical_columns_count = len(numericals_train_scaled.columns)\n",
    "\n",
    "# Create a list of tuples by pairing column names from 'numericals_train_scaled.columns' with values from 'var_list'\n",
    "\n",
    "# Pair each column name from 'numericals_train_scaled.columns' with its corresponding feature selection status from 'var_list'\n",
    "# The resulting list consists of tuples where each tuple contains a column name and its corresponding feature selection status\n",
    "selected_features_info = list(zip(numericals_train_scaled.columns, var_list))\n",
    "\n",
    "print(numerical_columns_count)\n",
    "selected_features_info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "249"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a list of column names to drop based on the boolean values in 'var_list'\n",
    "\n",
    "# Generate 'drop_list' by extracting column names from 'numericals_train_scaled' where corresponding values in 'var_list' are False\n",
    "drop_list = [col[0] for col in zip(numericals_train_scaled.columns, var_list) if col[1] == False]\n",
    "\n",
    "# Calculate the length of 'drop_list'\n",
    "len(drop_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "there are 249 columns that could be dropped as a result of having a low variance feature.\n",
    "\n",
    "k-best will also ve used to further reduce the number of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ODATEDW</th>\n",
       "      <th>DOB</th>\n",
       "      <th>AGE</th>\n",
       "      <th>INCOME</th>\n",
       "      <th>WEALTH1</th>\n",
       "      <th>VIETVETS</th>\n",
       "      <th>WWIIVETS</th>\n",
       "      <th>WEALTH2</th>\n",
       "      <th>POP90C1</th>\n",
       "      <th>POP90C2</th>\n",
       "      <th>...</th>\n",
       "      <th>MHUC2</th>\n",
       "      <th>CARDPROM</th>\n",
       "      <th>LASTDATE</th>\n",
       "      <th>CONTROLN</th>\n",
       "      <th>HPHONE_D</th>\n",
       "      <th>RFA_2F</th>\n",
       "      <th>CLUSTER2</th>\n",
       "      <th>CLUSTER</th>\n",
       "      <th>DATASRCE</th>\n",
       "      <th>DOMAIN_B</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.928315</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.624862</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.212121</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.497487</td>\n",
       "      <td>0.472526</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.426230</td>\n",
       "      <td>0.019231</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.498208</td>\n",
       "      <td>0.350257</td>\n",
       "      <td>0.649485</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.232323</td>\n",
       "      <td>0.282828</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.030151</td>\n",
       "      <td>0.098807</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.950820</td>\n",
       "      <td>0.192308</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.354839</td>\n",
       "      <td>0.360556</td>\n",
       "      <td>0.639175</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.433333</td>\n",
       "      <td>0.492462</td>\n",
       "      <td>0.307856</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.852459</td>\n",
       "      <td>0.673077</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.354839</td>\n",
       "      <td>0.267868</td>\n",
       "      <td>0.731959</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.191919</td>\n",
       "      <td>0.303030</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>0.015075</td>\n",
       "      <td>0.429001</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.344262</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.426523</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.624862</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.464646</td>\n",
       "      <td>0.383838</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.045226</td>\n",
       "      <td>0.733875</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.688525</td>\n",
       "      <td>0.807692</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76324</th>\n",
       "      <td>0.862366</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.624862</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.030151</td>\n",
       "      <td>0.865417</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.180328</td>\n",
       "      <td>0.423077</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76325</th>\n",
       "      <td>0.713262</td>\n",
       "      <td>0.370855</td>\n",
       "      <td>0.628866</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.313131</td>\n",
       "      <td>0.323232</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.045226</td>\n",
       "      <td>0.314400</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.360656</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76326</th>\n",
       "      <td>0.569892</td>\n",
       "      <td>0.556231</td>\n",
       "      <td>0.443299</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.141414</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.366667</td>\n",
       "      <td>0.010050</td>\n",
       "      <td>0.087414</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.311475</td>\n",
       "      <td>0.211538</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76327</th>\n",
       "      <td>0.784946</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.624862</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.474747</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.183333</td>\n",
       "      <td>0.492462</td>\n",
       "      <td>0.549046</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.950820</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76328</th>\n",
       "      <td>0.641577</td>\n",
       "      <td>0.495366</td>\n",
       "      <td>0.494845</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.497487</td>\n",
       "      <td>0.044202</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.114754</td>\n",
       "      <td>0.403846</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76329 rows × 85 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ODATEDW       DOB       AGE    INCOME   WEALTH1  VIETVETS  WWIIVETS  \\\n",
       "0      0.928315  0.000000  0.624862  0.666667  0.555556  0.363636  0.212121   \n",
       "1      0.498208  0.350257  0.649485  0.500000  0.555556  0.232323  0.282828   \n",
       "2      0.354839  0.360556  0.639175  1.000000  0.666667  0.272727  0.333333   \n",
       "3      0.354839  0.267868  0.731959  0.166667  0.555556  0.191919  0.303030   \n",
       "4      0.426523  0.000000  0.624862  0.000000  0.555556  0.464646  0.383838   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "76324  0.862366  0.000000  0.624862  0.000000  0.777778  0.000000  0.000000   \n",
       "76325  0.713262  0.370855  0.628866  0.166667  0.222222  0.313131  0.323232   \n",
       "76326  0.569892  0.556231  0.443299  0.666667  0.555556  0.555556  0.141414   \n",
       "76327  0.784946  0.000000  0.624862  0.166667  0.555556  0.222222  0.474747   \n",
       "76328  0.641577  0.495366  0.494845  0.500000  0.555556  0.545455  0.222222   \n",
       "\n",
       "        WEALTH2  POP90C1   POP90C2  ...  MHUC2  CARDPROM  LASTDATE  CONTROLN  \\\n",
       "0      0.555556      1.0  0.000000  ...    0.6  0.066667  0.497487  0.472526   \n",
       "1      1.000000      0.0  0.000000  ...    0.4  0.400000  0.030151  0.098807   \n",
       "2      0.555556      0.0  0.636364  ...    0.4  0.433333  0.492462  0.307856   \n",
       "3      0.555556      1.0  0.000000  ...    0.4  0.450000  0.015075  0.429001   \n",
       "4      0.222222      0.0  0.000000  ...    0.6  0.300000  0.045226  0.733875   \n",
       "...         ...      ...       ...  ...    ...       ...       ...       ...   \n",
       "76324  0.555556      1.0  0.000000  ...    0.6  0.100000  0.030151  0.865417   \n",
       "76325  0.222222      1.0  0.000000  ...    0.4  0.300000  0.045226  0.314400   \n",
       "76326  1.000000      1.0  0.000000  ...    0.4  0.366667  0.010050  0.087414   \n",
       "76327  0.555556      0.0  0.555556  ...    0.4  0.183333  0.492462  0.549046   \n",
       "76328  0.777778      1.0  0.000000  ...    0.6  0.333333  0.497487  0.044202   \n",
       "\n",
       "       HPHONE_D    RFA_2F  CLUSTER2   CLUSTER  DATASRCE  DOMAIN_B  \n",
       "0           1.0  0.000000  0.426230  0.019231  0.000000  0.000000  \n",
       "1           0.0  0.333333  0.950820  0.192308  0.666667  0.000000  \n",
       "2           1.0  0.333333  0.852459  0.673077  1.000000  0.333333  \n",
       "3           1.0  0.000000  0.344262  0.384615  0.666667  0.666667  \n",
       "4           1.0  0.000000  0.688525  0.807692  0.666667  0.333333  \n",
       "...         ...       ...       ...       ...       ...       ...  \n",
       "76324       0.0  0.000000  0.180328  0.423077  0.333333  0.000000  \n",
       "76325       0.0  0.333333  0.360656  0.384615  0.333333  0.666667  \n",
       "76326       0.0  0.333333  0.311475  0.211538  0.666667  0.000000  \n",
       "76327       1.0  0.000000  0.950820  0.846154  0.666667  0.333333  \n",
       "76328       1.0  1.000000  0.114754  0.403846  0.666667  0.000000  \n",
       "\n",
       "[76329 rows x 85 columns]"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check k-best option to get an even smaller number of features\n",
    "\n",
    "# Remove features listed in 'drop_list' from the scaled numerical training features\n",
    "X_train_feature_num = numericals_train_scaled.drop(drop_list, axis=1)\n",
    "\n",
    "# Display the resulting DataFrame containing the reduced number of numerical features\n",
    "X_train_feature_num\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ODATEDW</th>\n",
       "      <th>DOB</th>\n",
       "      <th>AGE</th>\n",
       "      <th>INCOME</th>\n",
       "      <th>WEALTH1</th>\n",
       "      <th>VIETVETS</th>\n",
       "      <th>WWIIVETS</th>\n",
       "      <th>WEALTH2</th>\n",
       "      <th>POP90C1</th>\n",
       "      <th>POP90C2</th>\n",
       "      <th>...</th>\n",
       "      <th>RFA_2A_G</th>\n",
       "      <th>GEOCODE2_A</th>\n",
       "      <th>GEOCODE2_B</th>\n",
       "      <th>GEOCODE2_C</th>\n",
       "      <th>GEOCODE2_D</th>\n",
       "      <th>DOMAIN_A_C</th>\n",
       "      <th>DOMAIN_A_R</th>\n",
       "      <th>DOMAIN_A_S</th>\n",
       "      <th>DOMAIN_A_T</th>\n",
       "      <th>DOMAIN_A_U</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.928315</td>\n",
       "      <td>0.597425</td>\n",
       "      <td>0.402062</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.191919</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.929293</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.569892</td>\n",
       "      <td>0.237178</td>\n",
       "      <td>0.762887</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.343434</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.784946</td>\n",
       "      <td>0.473841</td>\n",
       "      <td>0.525773</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.191919</td>\n",
       "      <td>0.080808</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.713262</td>\n",
       "      <td>0.453244</td>\n",
       "      <td>0.546392</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.202020</td>\n",
       "      <td>0.242424</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.569892</td>\n",
       "      <td>0.432647</td>\n",
       "      <td>0.567010</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.080808</td>\n",
       "      <td>0.767677</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19078</th>\n",
       "      <td>0.784946</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.624862</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.303030</td>\n",
       "      <td>0.343434</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19079</th>\n",
       "      <td>0.784946</td>\n",
       "      <td>0.329660</td>\n",
       "      <td>0.670103</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.262626</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19080</th>\n",
       "      <td>0.784946</td>\n",
       "      <td>0.484140</td>\n",
       "      <td>0.515464</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.343434</td>\n",
       "      <td>0.424242</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19081</th>\n",
       "      <td>0.928315</td>\n",
       "      <td>0.607724</td>\n",
       "      <td>0.391753</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.313131</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19082</th>\n",
       "      <td>0.211470</td>\n",
       "      <td>0.340371</td>\n",
       "      <td>0.659794</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.191919</td>\n",
       "      <td>0.404040</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19083 rows × 117 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ODATEDW       DOB       AGE    INCOME   WEALTH1  VIETVETS  WWIIVETS  \\\n",
       "0      0.928315  0.597425  0.402062  0.833333  1.000000  0.333333  0.191919   \n",
       "1      0.569892  0.237178  0.762887  0.666667  0.555556  0.333333  0.343434   \n",
       "2      0.784946  0.473841  0.525773  1.000000  1.000000  0.191919  0.080808   \n",
       "3      0.713262  0.453244  0.546392  1.000000  0.555556  0.202020  0.242424   \n",
       "4      0.569892  0.432647  0.567010  0.666667  0.666667  0.080808  0.767677   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "19078  0.784946  0.000000  0.624862  0.666667  0.555556  0.303030  0.343434   \n",
       "19079  0.784946  0.329660  0.670103  0.666667  0.555556  0.000000  0.262626   \n",
       "19080  0.784946  0.484140  0.515464  0.833333  1.000000  0.343434  0.424242   \n",
       "19081  0.928315  0.607724  0.391753  0.500000  0.333333  0.313131  0.444444   \n",
       "19082  0.211470  0.340371  0.659794  0.333333  0.888889  0.191919  0.404040   \n",
       "\n",
       "        WEALTH2   POP90C1  POP90C2  ...  RFA_2A_G  GEOCODE2_A  GEOCODE2_B  \\\n",
       "0      0.555556  0.929293      0.0  ...       1.0         0.0         0.0   \n",
       "1      0.333333  1.000000      0.0  ...       0.0         1.0         0.0   \n",
       "2      0.555556  1.000000      0.0  ...       0.0         1.0         0.0   \n",
       "3      0.555556  1.000000      0.0  ...       0.0         1.0         0.0   \n",
       "4      0.666667  0.000000      0.0  ...       1.0         1.0         0.0   \n",
       "...         ...       ...      ...  ...       ...         ...         ...   \n",
       "19078  0.555556  0.000000      0.0  ...       0.0         0.0         0.0   \n",
       "19079  0.555556  1.000000      0.0  ...       0.0         1.0         0.0   \n",
       "19080  0.555556  1.000000      0.0  ...       0.0         0.0         1.0   \n",
       "19081  0.555556  1.000000      0.0  ...       0.0         0.0         1.0   \n",
       "19082  0.888889  0.000000      0.0  ...       1.0         0.0         0.0   \n",
       "\n",
       "       GEOCODE2_C  GEOCODE2_D  DOMAIN_A_C  DOMAIN_A_R  DOMAIN_A_S  DOMAIN_A_T  \\\n",
       "0             1.0         0.0         0.0         0.0         1.0         0.0   \n",
       "1             0.0         0.0         0.0         0.0         1.0         0.0   \n",
       "2             0.0         0.0         0.0         0.0         0.0         0.0   \n",
       "3             0.0         0.0         0.0         0.0         1.0         0.0   \n",
       "4             0.0         0.0         1.0         0.0         0.0         0.0   \n",
       "...           ...         ...         ...         ...         ...         ...   \n",
       "19078         1.0         0.0         0.0         1.0         0.0         0.0   \n",
       "19079         0.0         0.0         0.0         0.0         1.0         0.0   \n",
       "19080         0.0         0.0         0.0         0.0         1.0         0.0   \n",
       "19081         0.0         0.0         0.0         0.0         0.0         0.0   \n",
       "19082         0.0         1.0         1.0         0.0         0.0         0.0   \n",
       "\n",
       "       DOMAIN_A_U  \n",
       "0             0.0  \n",
       "1             0.0  \n",
       "2             1.0  \n",
       "3             0.0  \n",
       "4             0.0  \n",
       "...           ...  \n",
       "19078         0.0  \n",
       "19079         0.0  \n",
       "19080         0.0  \n",
       "19081         1.0  \n",
       "19082         0.0  \n",
       "\n",
       "[19083 rows x 117 columns]"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_feature = X_test.drop(drop_list, axis = 1)\n",
    "X_test_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(76329, 85)\n",
      "(76329, 25)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.928315</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.020202</td>\n",
       "      <td>0.215667</td>\n",
       "      <td>0.226000</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.080808</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.757576</td>\n",
       "      <td>...</td>\n",
       "      <td>0.969697</td>\n",
       "      <td>0.170940</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.575758</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.497487</td>\n",
       "      <td>0.472526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.426230</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.498208</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.010101</td>\n",
       "      <td>0.080500</td>\n",
       "      <td>0.111500</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.020202</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.191919</td>\n",
       "      <td>...</td>\n",
       "      <td>0.212121</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.424242</td>\n",
       "      <td>0.646465</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.030151</td>\n",
       "      <td>0.098807</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.950820</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.354839</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.050505</td>\n",
       "      <td>0.066000</td>\n",
       "      <td>0.075667</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010101</td>\n",
       "      <td>0.040404</td>\n",
       "      <td>...</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.353535</td>\n",
       "      <td>0.868687</td>\n",
       "      <td>0.433333</td>\n",
       "      <td>0.492462</td>\n",
       "      <td>0.307856</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.852459</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.354839</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.010101</td>\n",
       "      <td>0.121833</td>\n",
       "      <td>0.127167</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.010101</td>\n",
       "      <td>0.010101</td>\n",
       "      <td>0.101010</td>\n",
       "      <td>...</td>\n",
       "      <td>0.858586</td>\n",
       "      <td>0.547009</td>\n",
       "      <td>0.343434</td>\n",
       "      <td>0.868687</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>0.015075</td>\n",
       "      <td>0.429001</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.344262</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.426523</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.113167</td>\n",
       "      <td>0.119000</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.131313</td>\n",
       "      <td>...</td>\n",
       "      <td>0.595960</td>\n",
       "      <td>0.440171</td>\n",
       "      <td>0.404040</td>\n",
       "      <td>0.171717</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.045226</td>\n",
       "      <td>0.733875</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.688525</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5         6   \\\n",
       "0  0.928315  0.666667  0.020202  0.215667  0.226000  0.384615  0.384615   \n",
       "1  0.498208  0.500000  0.010101  0.080500  0.111500  0.153846  0.153846   \n",
       "2  0.354839  1.000000  0.050505  0.066000  0.075667  0.153846  0.153846   \n",
       "3  0.354839  0.166667  0.010101  0.121833  0.127167  0.307692  0.307692   \n",
       "4  0.426523  0.000000  0.000000  0.113167  0.119000  0.230769  0.230769   \n",
       "\n",
       "         7         8         9   ...        15        16        17        18  \\\n",
       "0  0.080808  0.363636  0.757576  ...  0.969697  0.170940  0.454545  0.575758   \n",
       "1  0.020202  0.090909  0.191919  ...  0.212121  0.000000  0.424242  0.646465   \n",
       "2  0.000000  0.010101  0.040404  ...  0.111111  0.000000  0.353535  0.868687   \n",
       "3  0.010101  0.010101  0.101010  ...  0.858586  0.547009  0.343434  0.868687   \n",
       "4  0.000000  0.000000  0.131313  ...  0.595960  0.440171  0.404040  0.171717   \n",
       "\n",
       "         19        20        21        22        23        24  \n",
       "0  0.066667  0.497487  0.472526  0.000000  0.426230  0.000000  \n",
       "1  0.400000  0.030151  0.098807  0.333333  0.950820  0.000000  \n",
       "2  0.433333  0.492462  0.307856  0.333333  0.852459  0.333333  \n",
       "3  0.450000  0.015075  0.429001  0.000000  0.344262  0.666667  \n",
       "4  0.300000  0.045226  0.733875  0.000000  0.688525  0.333333  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import necessary libraries for feature selection\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "# Print the shape of the original numerical training features\n",
    "print(X_train_feature_num.shape)\n",
    "\n",
    "# Instantiate SelectKBest with chi-squared scoring function and k=25, transform the training features\n",
    "K_best = SelectKBest(chi2, k=25).fit_transform(X_train_feature_num, y_train)\n",
    "\n",
    "# Print the shape of the transformed features after feature selection\n",
    "print(K_best.shape)\n",
    "\n",
    "# Convert the transformed features into a DataFrame and display the first few rows\n",
    "selected = pd.DataFrame(K_best)\n",
    "selected.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(85, 2)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>column_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>164.877627</td>\n",
       "      <td>RFA_2F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>31.438727</td>\n",
       "      <td>LASTDATE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>18.568170</td>\n",
       "      <td>HVP1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>18.040893</td>\n",
       "      <td>HVP2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>16.683462</td>\n",
       "      <td>HVP3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>15.930991</td>\n",
       "      <td>HVP6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>12.845856</td>\n",
       "      <td>HVP4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>11.695771</td>\n",
       "      <td>ETH2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>9.871114</td>\n",
       "      <td>RP1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.664763</td>\n",
       "      <td>ODATEDW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>8.424504</td>\n",
       "      <td>RP2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>6.580288</td>\n",
       "      <td>CARDPROM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>6.434152</td>\n",
       "      <td>HV1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>6.420312</td>\n",
       "      <td>HV2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>5.330840</td>\n",
       "      <td>DOMAIN_B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>4.849141</td>\n",
       "      <td>HVP5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>4.350268</td>\n",
       "      <td>RP3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>3.699414</td>\n",
       "      <td>CLUSTER2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>3.347154</td>\n",
       "      <td>MSA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.029531</td>\n",
       "      <td>INCOME</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2.912156</td>\n",
       "      <td>HV3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2.849850</td>\n",
       "      <td>HV4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>2.468075</td>\n",
       "      <td>CONTROLN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>2.290709</td>\n",
       "      <td>POBC2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>2.145176</td>\n",
       "      <td>HHAS3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>1.612186</td>\n",
       "      <td>MHUC1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.608114</td>\n",
       "      <td>WEALTH2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>1.569653</td>\n",
       "      <td>HC6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>1.493762</td>\n",
       "      <td>HC8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1.401708</td>\n",
       "      <td>HU5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>1.361075</td>\n",
       "      <td>IC6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.350982</td>\n",
       "      <td>POP90C3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.250864</td>\n",
       "      <td>ETH1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>1.188022</td>\n",
       "      <td>RP4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>1.124945</td>\n",
       "      <td>HC5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>1.043071</td>\n",
       "      <td>HC7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.009306</td>\n",
       "      <td>POP90C1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>0.959740</td>\n",
       "      <td>HC4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>0.919094</td>\n",
       "      <td>HC2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.814738</td>\n",
       "      <td>ADI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>0.668324</td>\n",
       "      <td>HC18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>0.654898</td>\n",
       "      <td>CLUSTER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>0.654239</td>\n",
       "      <td>VC3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.573343</td>\n",
       "      <td>HUR2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.542406</td>\n",
       "      <td>WEALTH1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>0.523756</td>\n",
       "      <td>HC13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.460224</td>\n",
       "      <td>PEC2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.444230</td>\n",
       "      <td>ETHC2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>0.416957</td>\n",
       "      <td>VOC2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.415003</td>\n",
       "      <td>MC1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         score column_name\n",
       "80  164.877627      RFA_2F\n",
       "77   31.438727    LASTDATE\n",
       "30   18.568170        HVP1\n",
       "31   18.040893        HVP2\n",
       "32   16.683462        HVP3\n",
       "35   15.930991        HVP6\n",
       "33   12.845856        HVP4\n",
       "12   11.695771        ETH2\n",
       "40    9.871114         RP1\n",
       "0     9.664763     ODATEDW\n",
       "41    8.424504         RP2\n",
       "76    6.580288    CARDPROM\n",
       "19    6.434152         HV1\n",
       "20    6.420312         HV2\n",
       "84    5.330840    DOMAIN_B\n",
       "34    4.849141        HVP5\n",
       "42    4.350268         RP3\n",
       "81    3.699414    CLUSTER2\n",
       "44    3.347154         MSA\n",
       "3     3.029531      INCOME\n",
       "21    2.912156         HV3\n",
       "22    2.849850         HV4\n",
       "78    2.468075    CONTROLN\n",
       "60    2.290709       POBC2\n",
       "47    2.145176       HHAS3\n",
       "74    1.612186       MHUC1\n",
       "7     1.608114     WEALTH2\n",
       "66    1.569653         HC6\n",
       "68    1.493762         HC8\n",
       "25    1.401708         HU5\n",
       "46    1.361075         IC6\n",
       "10    1.350982     POP90C3\n",
       "11    1.250864        ETH1\n",
       "43    1.188022         RP4\n",
       "65    1.124945         HC5\n",
       "67    1.043071         HC7\n",
       "8     1.009306     POP90C1\n",
       "64    0.959740         HC4\n",
       "63    0.919094         HC2\n",
       "45    0.814738         ADI\n",
       "72    0.668324        HC18\n",
       "82    0.654898     CLUSTER\n",
       "59    0.654239         VC3\n",
       "36    0.573343        HUR2\n",
       "4     0.542406     WEALTH1\n",
       "70    0.523756        HC13\n",
       "50    0.460224        PEC2\n",
       "29    0.444230       ETHC2\n",
       "62    0.416957        VOC2\n",
       "48    0.415003         MC1"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate SelectKBest with chi-squared scoring function and k=25, fit it to the training numerical features and target\n",
    "model = SelectKBest(chi2, k=25).fit(X_train_feature_num, y_train)\n",
    "\n",
    "# Create a DataFrame to store the scores and corresponding column names\n",
    "df = pd.DataFrame(data=model.scores_, columns=['score'])\n",
    "df['column_name'] = X_train_feature_num.columns  # Add column names to the DataFrame\n",
    "\n",
    "# Display the shape of the DataFrame and its contents\n",
    "display(df.shape)  \n",
    "df \n",
    "\n",
    "# Sort the DataFrame by the 'score' column in descending order, take the top 50 rows, and display the result\n",
    "df.sort_values(by=['score'], ascending=False).head(50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RFA_2F',\n",
       " 'LASTDATE',\n",
       " 'HVP1',\n",
       " 'HVP2',\n",
       " 'HVP3',\n",
       " 'HVP6',\n",
       " 'HVP4',\n",
       " 'ETH2',\n",
       " 'RP1',\n",
       " 'ODATEDW',\n",
       " 'RP2',\n",
       " 'CARDPROM',\n",
       " 'HV1',\n",
       " 'HV2',\n",
       " 'DOMAIN_B',\n",
       " 'HVP5',\n",
       " 'RP3',\n",
       " 'CLUSTER2',\n",
       " 'MSA',\n",
       " 'INCOME',\n",
       " 'HV3',\n",
       " 'HV4',\n",
       " 'CONTROLN',\n",
       " 'POBC2',\n",
       " 'HHAS3']"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sort the DataFrame by the 'score' column in descending order, take the top 25 rows, and extract the 'column_name' values\n",
    "cols_sort = df.sort_values(by=['score'], ascending=False).head(25)['column_name']\n",
    "\n",
    "# Convert the extracted column names into a list\n",
    "col_list = list(cols_sort)\n",
    "\n",
    "col_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(76329, 57)\n",
      "(19083, 57)\n"
     ]
    }
   ],
   "source": [
    "# Applying reduction of features to the test and train datasets\n",
    "\n",
    "# Selecting only the columns chosen from feature selection for the training dataset\n",
    "X_train_feature = numericals_train_scaled[col_list]\n",
    "X_train_feature = pd.concat([X_train_feature, categoricals_train_encoded], axis=1) \n",
    "print(X_train_feature.shape)  \n",
    "\n",
    "# Selecting only the columns chosen from feature selection for the test dataset\n",
    "X_test_feature = numericals_test_scaled[col_list] \n",
    "X_test_feature = pd.concat([X_test_feature, categoricals_test_encoded], axis=1) \n",
    "print(X_test_feature.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the resample function from sklearn.utils\n",
    "from sklearn.utils import resample\n",
    "\n",
    "# Concatenate features and target variable for training data\n",
    "train = pd.concat([X_train_feature, y_train], axis = 1)\n",
    "\n",
    "# Separate the training data into two categories based on the target variable values\n",
    "category_0 = train[train['TARGET_B'] == 0]  \n",
    "category_1 = train[train['TARGET_B'] == 1]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Undersample the majority class (category_0) to match the number of samples in the minority class (category_1)\n",
    "category_0_undersampled = resample(category_0,\n",
    "                                   replace=False, \n",
    "                                   n_samples = len(category_1))  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3865, 58)\n",
      "(3865, 58)\n"
     ]
    }
   ],
   "source": [
    "print(category_0_undersampled.shape)\n",
    "print(category_1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate the two dataframes vertically to create a downsampled dataset\n",
    "data_downsampled = pd.concat([category_0_undersampled, category_1], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RFA_2F</th>\n",
       "      <th>LASTDATE</th>\n",
       "      <th>HVP1</th>\n",
       "      <th>HVP2</th>\n",
       "      <th>HVP3</th>\n",
       "      <th>HVP6</th>\n",
       "      <th>HVP4</th>\n",
       "      <th>ETH2</th>\n",
       "      <th>RP1</th>\n",
       "      <th>ODATEDW</th>\n",
       "      <th>...</th>\n",
       "      <th>GEOCODE2_A</th>\n",
       "      <th>GEOCODE2_B</th>\n",
       "      <th>GEOCODE2_C</th>\n",
       "      <th>GEOCODE2_D</th>\n",
       "      <th>DOMAIN_A_C</th>\n",
       "      <th>DOMAIN_A_R</th>\n",
       "      <th>DOMAIN_A_S</th>\n",
       "      <th>DOMAIN_A_T</th>\n",
       "      <th>DOMAIN_A_U</th>\n",
       "      <th>TARGET_B</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6279</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.040201</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.161616</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.626263</td>\n",
       "      <td>0.030303</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.569892</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43894</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.492462</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010101</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.191919</td>\n",
       "      <td>0.989899</td>\n",
       "      <td>0.060606</td>\n",
       "      <td>0.928315</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63447</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.030151</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010101</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.040404</td>\n",
       "      <td>0.010101</td>\n",
       "      <td>0.010101</td>\n",
       "      <td>0.928315</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28366</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.045226</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010101</td>\n",
       "      <td>0.060606</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.191919</td>\n",
       "      <td>0.121212</td>\n",
       "      <td>0.010101</td>\n",
       "      <td>0.784946</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6510</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.040201</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.856631</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76183</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.497487</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.020202</td>\n",
       "      <td>0.969697</td>\n",
       "      <td>0.505051</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.856631</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76188</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.492462</td>\n",
       "      <td>0.484848</td>\n",
       "      <td>0.757576</td>\n",
       "      <td>0.929293</td>\n",
       "      <td>0.131313</td>\n",
       "      <td>0.969697</td>\n",
       "      <td>0.030303</td>\n",
       "      <td>0.474747</td>\n",
       "      <td>0.641577</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76219</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.025126</td>\n",
       "      <td>0.838384</td>\n",
       "      <td>0.959596</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.484848</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.464646</td>\n",
       "      <td>0.641577</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76245</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.502513</td>\n",
       "      <td>0.010101</td>\n",
       "      <td>0.030303</td>\n",
       "      <td>0.131313</td>\n",
       "      <td>0.010101</td>\n",
       "      <td>0.282828</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.283154</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76251</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015075</td>\n",
       "      <td>0.505051</td>\n",
       "      <td>0.505051</td>\n",
       "      <td>0.505051</td>\n",
       "      <td>0.505051</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.151515</td>\n",
       "      <td>0.040404</td>\n",
       "      <td>0.784946</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7730 rows × 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         RFA_2F  LASTDATE      HVP1      HVP2      HVP3      HVP6      HVP4  \\\n",
       "6279   0.000000  0.040201  0.000000  0.000000  0.161616  0.000000  0.626263   \n",
       "43894  0.000000  0.492462  0.000000  0.000000  0.010101  0.000000  0.191919   \n",
       "63447  0.000000  0.030151  0.000000  0.000000  0.010101  0.000000  0.040404   \n",
       "28366  0.000000  0.045226  0.000000  0.010101  0.060606  0.000000  0.191919   \n",
       "6510   0.000000  0.040201  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "76183  1.000000  0.497487  0.333333  0.727273  0.909091  0.020202  0.969697   \n",
       "76188  0.333333  0.492462  0.484848  0.757576  0.929293  0.131313  0.969697   \n",
       "76219  0.333333  0.025126  0.838384  0.959596  1.000000  0.484848  1.000000   \n",
       "76245  1.000000  0.502513  0.010101  0.030303  0.131313  0.010101  0.282828   \n",
       "76251  0.000000  0.015075  0.505051  0.505051  0.505051  0.505051  1.000000   \n",
       "\n",
       "           ETH2       RP1   ODATEDW  ...  GEOCODE2_A  GEOCODE2_B  GEOCODE2_C  \\\n",
       "6279   0.030303  0.181818  0.569892  ...         0.0         1.0         0.0   \n",
       "43894  0.989899  0.060606  0.928315  ...         1.0         0.0         0.0   \n",
       "63447  0.010101  0.010101  0.928315  ...         1.0         0.0         0.0   \n",
       "28366  0.121212  0.010101  0.784946  ...         0.0         0.0         0.0   \n",
       "6510   0.272727  0.000000  0.856631  ...         0.0         1.0         0.0   \n",
       "...         ...       ...       ...  ...         ...         ...         ...   \n",
       "76183  0.505051  0.272727  0.856631  ...         1.0         0.0         0.0   \n",
       "76188  0.030303  0.474747  0.641577  ...         1.0         0.0         0.0   \n",
       "76219  0.000000  0.464646  0.641577  ...         1.0         0.0         0.0   \n",
       "76245  0.000000  0.000000  0.283154  ...         0.0         1.0         0.0   \n",
       "76251  0.151515  0.040404  0.784946  ...         1.0         0.0         0.0   \n",
       "\n",
       "       GEOCODE2_D  DOMAIN_A_C  DOMAIN_A_R  DOMAIN_A_S  DOMAIN_A_T  DOMAIN_A_U  \\\n",
       "6279          0.0         0.0         0.0         1.0         0.0         0.0   \n",
       "43894         0.0         0.0         0.0         0.0         0.0         1.0   \n",
       "63447         0.0         1.0         0.0         0.0         0.0         0.0   \n",
       "28366         1.0         0.0         1.0         0.0         0.0         0.0   \n",
       "6510          0.0         1.0         0.0         0.0         0.0         0.0   \n",
       "...           ...         ...         ...         ...         ...         ...   \n",
       "76183         0.0         0.0         0.0         0.0         0.0         1.0   \n",
       "76188         0.0         0.0         0.0         0.0         0.0         1.0   \n",
       "76219         0.0         0.0         0.0         0.0         0.0         1.0   \n",
       "76245         0.0         0.0         1.0         0.0         0.0         0.0   \n",
       "76251         0.0         0.0         0.0         0.0         0.0         1.0   \n",
       "\n",
       "       TARGET_B  \n",
       "6279          0  \n",
       "43894         0  \n",
       "63447         0  \n",
       "28366         0  \n",
       "6510          0  \n",
       "...         ...  \n",
       "76183         1  \n",
       "76188         1  \n",
       "76219         1  \n",
       "76245         1  \n",
       "76251         1  \n",
       "\n",
       "[7730 rows x 58 columns]"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_downsampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    3865\n",
       "1    3865\n",
       "Name: TARGET_B, dtype: int64"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_downsampled['TARGET_B'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X y split - Separate features and target variable for downsampled training data\n",
    "X_train_down = data_downsampled.drop(['TARGET_B'],axis=1)\n",
    "y_train_down = data_downsampled['TARGET_B']  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.598438400670754\n",
      "precision:  0.07075895723641967\n",
      "recall:  0.5633946830265849\n",
      "f1:  0.12572732458642327\n"
     ]
    }
   ],
   "source": [
    "# Train a logistic regression classifier using the downsampled training data\n",
    "LR_down = LogisticRegression(random_state=42, solver='lbfgs', max_iter=4000).fit(X_train_down, y_train_down)\n",
    "\n",
    "# Predict using the trained model on the test set\n",
    "pred_down = LR_down.predict(X_test_feature)\n",
    "\n",
    "# Print evaluation metrics\n",
    "print('accuracy:', accuracy_score(y_test, pred_down))  # Print accuracy\n",
    "print(\"precision: \",precision_score(y_test,pred_down))  # Print precision\n",
    "print(\"recall: \",recall_score(y_test,pred_down))  # Print recall\n",
    "print(\"f1: \",f1_score(y_test,pred_down))  # Print F1 score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_1_oversampled = resample(category_1,\n",
    "                                  replace=True,\n",
    "                                  n_samples = len(category_0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(72464, 58)\n",
      "(72464, 58)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(category_0.shape)\n",
    "print(category_1_oversampled.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate the oversampled minority class (category_1_oversampled) with the majority class (category_0)\n",
    "# to create the up-sampled dataset (data_upsampled)\n",
    "data_upsampled = pd.concat([category_0, category_1_oversampled], axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    72464\n",
       "1    72464\n",
       "Name: TARGET_B, dtype: int64"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count the occurrences of each class in the up-sampled target variable\n",
    "data_upsampled['TARGET_B'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate the features (independent variables) and the target variable (dependent variable) for the up-sampled data\n",
    "X_train_up = data_upsampled.drop(['TARGET_B'], axis=1)  \n",
    "y_train_up = data_upsampled['TARGET_B']  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.6147356285699314\n",
      "precision:  0.07347430406852248\n",
      "recall:  0.5613496932515337\n",
      "f1:  0.12994082840236687\n"
     ]
    }
   ],
   "source": [
    "# Train the Logistic Regression model on the up-sampled training data\n",
    "LR_up = LogisticRegression(random_state=42, solver='lbfgs', max_iter=4000).fit(X_train_up, y_train_up)\n",
    "\n",
    "# Make predictions using the trained model on the test data\n",
    "pred_up = LR_up.predict(X_test_feature)\n",
    "\n",
    "# Evaluate the performance of the model by computing and printing different metrics\n",
    "print('accuracy:', accuracy_score(y_test, pred_up))\n",
    "print(\"precision: \", precision_score(y_test, pred_up))  \n",
    "print(\"recall: \", recall_score(y_test, pred_up)) \n",
    "print(\"f1: \", f1_score(y_test, pred_up))  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Up-sampled</th>\n",
       "      <td>0.614736</td>\n",
       "      <td>0.073474</td>\n",
       "      <td>0.561350</td>\n",
       "      <td>0.129941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Down-sampled</th>\n",
       "      <td>0.598438</td>\n",
       "      <td>0.070759</td>\n",
       "      <td>0.563395</td>\n",
       "      <td>0.125727</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              accuracy  precision    recall        f1\n",
       "Up-sampled    0.614736   0.073474  0.561350  0.129941\n",
       "Down-sampled  0.598438   0.070759  0.563395  0.125727"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute evaluation table with results from oversampling and undersampling\n",
    "metrics_up = {\n",
    "    'accuracy': accuracy_score(y_test, pred_up),\n",
    "    'precision': precision_score(y_test, pred_up),\n",
    "    'recall': recall_score(y_test, pred_up),\n",
    "    'f1': f1_score(y_test, pred_up)\n",
    "}\n",
    "\n",
    "metrics_down = {\n",
    "    'accuracy': accuracy_score(y_test, pred_down),\n",
    "    'precision': precision_score(y_test, pred_down),\n",
    "    'recall': recall_score(y_test, pred_down),\n",
    "    'f1': f1_score(y_test, pred_down)\n",
    "}\n",
    "\n",
    "# Create a DataFrame from the metrics\n",
    "results_fs_up_down = pd.DataFrame([metrics_up, metrics_down], index=['Up-sampled', 'Down-sampled'])\n",
    "\n",
    "results_fs_up_down"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 800x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay  \n",
    "\n",
    "# Compute confusion matrix for the up-sampled Logistic Regression model\n",
    "cm_up = confusion_matrix(y_test, pred_up)\n",
    "\n",
    "# Display confusion matrix for the up-sampled model with a title\n",
    "plt.figure(figsize=(8, 6)) \n",
    "disp_up = ConfusionMatrixDisplay(confusion_matrix=cm_up)\n",
    "disp_up.plot(cmap=plt.cm.Blues)\n",
    "plt.title('Confusion Matrix - Up-sampled') \n",
    "plt.show()\n",
    "\n",
    "# Compute confusion matrix for the down-sampled Logistic Regression model\n",
    "cm_down = confusion_matrix(y_test, pred_down)\n",
    "\n",
    "# Display confusion matrix for the down-sampled model with a title\n",
    "plt.figure(figsize=(8, 6))  \n",
    "disp_down = ConfusionMatrixDisplay(confusion_matrix=cm_down)  \n",
    "disp_down.plot(cmap=plt.cm.Blues) \n",
    "plt.title('Confusion Matrix - Down-sampled') \n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discussion on Logistic Regression Model Performance for Identifying Potential Donors\n",
    "\n",
    "The logistic regression models trained on up-sampled and down-sampled data aimed to identify potential donors, a task critical for fundraising campaigns and non-profit organizations. The performance of these models was evaluated using key metrics: accuracy, precision, recall, and F1 score.\n",
    "\n",
    "##### 1. Accuracy:\n",
    "- The accuracy represents the proportion of correctly classified instances out of all instances.\n",
    "- The up-sampled model achieved an accuracy of approximately 61.29%, while the down-sampled model achieved slightly lower accuracy at around 59.93%.\n",
    "- Both models demonstrated moderate overall accuracy in predicting potential donors.\n",
    "\n",
    "##### 2. Precision:\n",
    "- Precision measures the proportion of true positive predictions out of all positive predictions made by the model.\n",
    "- The up-sampled model exhibited a precision of approximately 7.36%, while the down-sampled model had a slightly lower precision of around 7.19%.\n",
    "- Precision is particularly crucial in the context of identifying potential donors as it reflects the effectiveness of the model in minimizing false positive predictions, ensuring that resources are efficiently allocated to individuals likely to donate.\n",
    "\n",
    "##### 3. Recall:\n",
    "- Recall, also known as sensitivity or true positive rate, measures the proportion of true positives that were correctly identified by the model out of all actual positive instances.\n",
    "- The up-sampled model demonstrated a recall of approximately 56.54%, while the down-sampled model had a slightly higher recall of around 57.26%.\n",
    "- Recall is vital for identifying potential donors as it indicates the model's ability to capture all relevant positive instances, ensuring that no potential donors are overlooked.\n",
    "\n",
    "##### 4. F1 Score:\n",
    "- The F1 score is the harmonic mean of precision and recall, providing a balanced measure of the model's performance.\n",
    "- The up-sampled model achieved an F1 score of approximately 13.02%, while the down-sampled model had a slightly lower F1 score of around 12.78%.\n",
    "- The F1 score considers both precision and recall, making it a suitable metric for evaluating the overall effectiveness of the model in identifying potential donors.\n",
    "\n",
    "##### Conclusion:\n",
    "- Both logistic regression models demonstrated moderate performance in identifying potential donors, with similar accuracy but slightly different precision, recall, and F1 scores.\n",
    "- While the up-sampled model exhibited marginally higher recall, the down-sampled model showed slightly higher precision.\n",
    "- These results suggest that while both sampling techniques can improve model performance compared to imbalanced datasets, further optimization or exploration of alternative algorithms may be necessary to enhance the effectiveness of donor identification.\n",
    "\n",
    "- In conclusion, while logistic regression models trained on up-sampled and down-sampled data showed promise in identifying potential donors, further refinement and exploration of advanced techniques may be warranted to achieve optimal performance in fundraising campaigns and non-profit endeavors.\n",
    "\n",
    "**Given that both results show very similar results, downsamplig will be used, as we can achieve the same results for a lower computational cost.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using other classification models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.6147356285699314\n",
      "precision:  0.07347430406852248\n",
      "recall:  0.5613496932515337\n",
      "f1:  0.12994082840236687\n"
     ]
    }
   ],
   "source": [
    "# Train a Logistic Regression classifier using the upsampled training sets\n",
    "LR_up = LogisticRegression(random_state=42, solver='lbfgs', max_iter=4000).fit(X_train_up, y_train_up)\n",
    "\n",
    "# Predict the response for the test dataset using the trained Logistic Regression model\n",
    "pred_down = LR_up.predict(X_test_feature)\n",
    "\n",
    "# Evaluate the performance of the Logistic Regression Classifier using accuracy, precision, recall, and F1 score metrics\n",
    "print('accuracy:', accuracy_score(y_test, pred_down))\n",
    "print(\"precision: \",precision_score(y_test,pred_down))\n",
    "print(\"recall: \",recall_score(y_test,pred_down))\n",
    "print(\"f1: \",f1_score(y_test,pred_down))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.5088298485563066\n",
      "precision:  0.053979385825098286\n",
      "recall:  0.5194274028629857\n",
      "f1:  0.09779574550004813\n"
     ]
    }
   ],
   "source": [
    "# Load libraries\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics \n",
    "\n",
    "# Create Decision Tree classifer object\n",
    "clf = DecisionTreeClassifier()\n",
    "\n",
    "# Train Decision Tree Classifer\n",
    "clf = clf.fit(X_train_down, y_train_down)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_pred_down_feature_dt = clf.predict(X_test_feature)\n",
    "\n",
    "print('accuracy:', accuracy_score(y_test, y_pred_down_feature_dt))\n",
    "print(\"precision: \",precision_score(y_test,y_pred_down_feature_dt))\n",
    "print(\"recall: \",recall_score(y_test,y_pred_down_feature_dt))\n",
    "print(\"f1: \",f1_score(y_test,y_pred_down_feature_dt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.6350154587853063\n",
      "precision:  0.07363623415467882\n",
      "recall:  0.5286298568507157\n",
      "f1:  0.12926615826978372\n"
     ]
    }
   ],
   "source": [
    "# Import the Support Vector Machine (SVM) model from scikit-learn\n",
    "from sklearn import svm\n",
    "\n",
    "# Create an SVM Classifier with a linear kernel\n",
    "svm_m = svm.SVC(kernel='linear')\n",
    "\n",
    "# Train the SVM model using the downsampled training sets\n",
    "svm_m.fit(X_train_down, y_train_down)\n",
    "\n",
    "# Predict the response for the test dataset using the trained SVM model\n",
    "y_pred_svm_down_feature = svm_m.predict(X_test_feature)\n",
    "\n",
    "# Evaluate the performance of the SVM Classifier using accuracy, precision, recall, and F1 score metrics\n",
    "print('accuracy:', accuracy_score(y_test, y_pred_svm_down_feature))\n",
    "print(\"precision: \", precision_score(y_test, y_pred_svm_down_feature))\n",
    "print(\"recall: \", recall_score(y_test, y_pred_svm_down_feature))\n",
    "print(\"f1: \", f1_score(y_test, y_pred_svm_down_feature))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.536184038149138\n",
      "precision:  0.058935574229691874\n",
      "recall:  0.5378323108384458\n",
      "f1:  0.10623043522165\n"
     ]
    }
   ],
   "source": [
    "# Import the KNeighborsClassifier class from the scikit-learn library\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Initialize a KNeighborsClassifier with 5 neighbors\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "# Train the KNeighborsClassifier on the downsampled training data\n",
    "knn.fit(X_train_down, y_train_down)\n",
    "\n",
    "# Use the trained KNeighborsClassifier to predict the target variable for the test set\n",
    "y_pred_down_knn = knn.predict(X_test_feature)\n",
    "\n",
    "# Evaluate the performance of the KNeighborsClassifier using accuracy, precision, recall, and F1 score metrics\n",
    "print('accuracy:', accuracy_score(y_test, y_pred_down_knn))\n",
    "print(\"precision: \", precision_score(y_test, y_pred_down_knn))\n",
    "print(\"recall: \", recall_score(y_test, y_pred_down_knn))\n",
    "print(\"f1: \", f1_score(y_test, y_pred_down_knn))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>0.614736</td>\n",
       "      <td>0.073474</td>\n",
       "      <td>0.561350</td>\n",
       "      <td>0.129941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Tree Classifier</th>\n",
       "      <td>0.508830</td>\n",
       "      <td>0.053979</td>\n",
       "      <td>0.519427</td>\n",
       "      <td>0.097796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Support Vector Machine</th>\n",
       "      <td>0.635015</td>\n",
       "      <td>0.073636</td>\n",
       "      <td>0.528630</td>\n",
       "      <td>0.129266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>K Neighbours Classifier</th>\n",
       "      <td>0.536184</td>\n",
       "      <td>0.058936</td>\n",
       "      <td>0.537832</td>\n",
       "      <td>0.106230</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          accuracy  precision    recall        f1\n",
       "Logistic Regression       0.614736   0.073474  0.561350  0.129941\n",
       "Decision Tree Classifier  0.508830   0.053979  0.519427  0.097796\n",
       "Support Vector Machine    0.635015   0.073636  0.528630  0.129266\n",
       "K Neighbours Classifier   0.536184   0.058936  0.537832  0.106230"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute evaluation table with results from oversampling and undersampling\n",
    "Logistic_Regression = {\n",
    "    'accuracy': accuracy_score(y_test, pred_down),\n",
    "    \"precision\": precision_score(y_test, pred_down),\n",
    "    \"recall\": recall_score(y_test, pred_down),\n",
    "    \"f1\": f1_score(y_test, pred_down)\n",
    "}\n",
    "\n",
    "Decision_Tree_Classifier = {\n",
    "    'accuracy': accuracy_score(y_test, y_pred_down_feature_dt),\n",
    "    \"precision\": precision_score(y_test, y_pred_down_feature_dt),\n",
    "    \"recall\": recall_score(y_test, y_pred_down_feature_dt),\n",
    "    \"f1\": f1_score(y_test, y_pred_down_feature_dt)\n",
    "}\n",
    "\n",
    "Support_Vector_Machine = {\n",
    "    'accuracy': accuracy_score(y_test, y_pred_svm_down_feature),\n",
    "    \"precision\": precision_score(y_test, y_pred_svm_down_feature),\n",
    "    \"recall\": recall_score(y_test, y_pred_svm_down_feature),\n",
    "    \"f1\": f1_score(y_test, y_pred_svm_down_feature)\n",
    "}\n",
    "\n",
    "K_Neighbours_Classifier = {\n",
    "    'accuracy': accuracy_score(y_test, y_pred_down_knn),\n",
    "    \"precision\": precision_score(y_test, y_pred_down_knn),\n",
    "    \"recall\": recall_score(y_test, y_pred_down_knn),\n",
    "    \"f1\": f1_score(y_test, y_pred_down_knn)\n",
    "}\n",
    "\n",
    "# Create a DataFrame from the metrics\n",
    "results = pd.DataFrame([Logistic_Regression, Decision_Tree_Classifier, Support_Vector_Machine, K_Neighbours_Classifier],\n",
    "                       index=['Logistic Regression', 'Decision Tree Classifier', 'Support Vector Machine', 'K Neighbours Classifier'])\n",
    "\n",
    "results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While evaluating the performance of the four models, it becomes apparent that there is no significant difference in their overall performance. Across the board, all models demonstrate a moderate precision score ranging from 5% to 7%. Similarly, the ranges for recall fall between 51.9% to 56.1%, with the Decision Tree Classifier showing the lowest recall and Logistic Regression displaying the highest. Despite the minor variations, Logistic Regression consistently outperforms the other models, exhibiting the highest precision and recall. This suggests that Logistic Regression is better at correctly identifying potential donors compared to the other models. Therefore, based on its superior performance in both precision and recall, **Logistic Regression is the most suitable model for this dataset**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.5805690929099199\n",
      "precision:  0.06832145490292456\n",
      "recall:  0.5685071574642127\n",
      "f1:  0.12198332602018429\n"
     ]
    }
   ],
   "source": [
    "# Concatenate the training features and target variable\n",
    "train_nofs = pd.concat([X_train, y_train], axis=1)\n",
    "\n",
    "# Separate instances of class 0 and class 1 in the training data\n",
    "category_0_nofs = train_nofs[train_nofs['TARGET_B'] == 0]\n",
    "category_1_nofs = train_nofs[train_nofs['TARGET_B'] == 1]\n",
    "\n",
    "# Undersample instances of class 0 to match the number of instances of class 1\n",
    "category_0_undersampled_nofs = resample(category_0_nofs,\n",
    "                                        replace=False,\n",
    "                                        n_samples=len(category_1_nofs))\n",
    "\n",
    "# Combine the undersampled class 0 instances with the original class 1 instances\n",
    "data_downsampled_nofs = pd.concat([category_0_undersampled_nofs, category_1_nofs], axis=0)\n",
    "\n",
    "# Separate the features and target variable from the downsampled data\n",
    "X_train_down_nofs = data_downsampled_nofs.drop(['TARGET_B'], axis=1)\n",
    "y_train_down_nofs = data_downsampled_nofs['TARGET_B']\n",
    "\n",
    "# Train a logistic regression model on the downsampled data\n",
    "LR_nofs = LogisticRegression(random_state=42, solver='lbfgs', max_iter=4000).fit(X_train_down_nofs, y_train_down_nofs)\n",
    "\n",
    "# Predict the target variable for the test set using the trained model\n",
    "pred_nofs = LR_nofs.predict(X_test)\n",
    "\n",
    "# Evaluate the performance of the logistic regression model\n",
    "print('accuracy:', accuracy_score(y_test, pred_nofs))\n",
    "print(\"precision: \", precision_score(y_test, pred_nofs))\n",
    "print(\"recall: \", recall_score(y_test, pred_nofs))\n",
    "print(\"f1: \", f1_score(y_test, pred_nofs))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimating amount donated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the dataframe\n",
    "df = pd.concat([X,target], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subseting the datarame for people who have made a donation\n",
    "df_B1 = df[df['TARGET_B'] == 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop unwanted columns\n",
    "df_B1 = df_B1.drop(columns =['Unnamed: 0','TARGET_B'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x y split\n",
    "\n",
    "X_D = df_B1.drop(columns =['TARGET_D'])\n",
    "y_D = df_B1['TARGET_D']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting numerical and categorical from X \n",
    "\n",
    "numericals_D = X_D.select_dtypes(np.number)\n",
    "categoricals_D= X_D.select_dtypes(object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaling numerical values using min max scaler\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "transformer_D = MinMaxScaler().fit(numericals_D)\n",
    "\n",
    "numericals_D_scaled = pd.DataFrame(transformer_D.transform(numericals_D), columns = numericals_D.columns).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode categoricals using one hot encoder\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# fit the encoder using the train data\n",
    "encoder_D = OneHotEncoder(handle_unknown='error').fit(categoricals_D)\n",
    "\n",
    "# Get the original column names for both the test and train data\n",
    "cols_train = encoder_D.get_feature_names_out(input_features=categoricals_D.columns)\n",
    "\n",
    "# Replace the generated feature names with the original column names\n",
    "categoricals_D_encoded = pd.DataFrame(encoder_D.transform(categoricals_D).toarray(), columns=cols_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concat numerical an categoricals into separate tables for test and train samples\n",
    "X_D_scaled=pd.concat([numericals_D_scaled ,categoricals_D_encoded], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train_D, X_test_D, y_train_D, y_test_D = train_test_split(X_D_scaled, y_D, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 61.35876520147546\n",
      "Mean Absolute Error: 5.013766998016081\n",
      "R-squared: 0.5874227507776766\n"
     ]
    }
   ],
   "source": [
    "# using linear regression to estimate amount donated\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "reg = LinearRegression().fit(X_train_D, y_train_D)\n",
    "\n",
    "y_pred = reg.predict(X_test_D)\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "mse = mean_squared_error(y_test_D, y_pred)\n",
    "mae = mean_absolute_error(y_test_D, y_pred)\n",
    "r2 = r2_score(y_test_D, y_pred)\n",
    "\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "print(\"Mean Absolute Error:\", mae)\n",
    "print(\"R-squared:\", r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Principle Component Analysis (PCA) for Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(0.9)\n",
    "pca.fit(X_train_D)\n",
    "\n",
    "X_train_pca = pca.transform(X_train_D)\n",
    "X_test_pca = pca.transform(X_test_D)\n",
    "\n",
    "corr_pc = pd.DataFrame(X_train_pca).corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "exp_var_pca = pca.explained_variance_ratio_\n",
    "cum_sum_eigenvalues = np.cumsum(exp_var_pca)\n",
    "\n",
    "\n",
    "# Create the visualization plot\n",
    "plt.bar(range(0,len(exp_var_pca)), exp_var_pca, \n",
    "        alpha=0.5, align='center', label='Individual explained variance')\n",
    "plt.step(range(0,len(cum_sum_eigenvalues)), cum_sum_eigenvalues, \n",
    "         where='mid',label='Cumulative explained variance')\n",
    "plt.ylabel('Explained variance ratio')\n",
    "plt.xlabel('Principal component index')\n",
    "plt.legend(loc='best')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the graph above we can see that we can explain about 80% of the information contained in the dataset by using about 30 variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3874, 58)\n",
      "(969, 58)\n",
      "(3874,)\n",
      "(969,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_pca.shape)\n",
    "print(X_test_pca.shape)\n",
    "print (y_train_D.shape)\n",
    "print(y_test_D.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining a fucntion to automate model fitting and scoring \n",
    "\n",
    "def models_automation(models, X_train, y_train,X_test,y_test):\n",
    "    for model in models:\n",
    "        model.fit(X_train, y_train)\n",
    "        print(f\"{model.__class__.__name__}: Train -> {model.score(X_train, y_train)}, Test -> {model.score(X_test, y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearRegression: Train -> 0.38764219147166346, Test -> 0.37695585063133796\n",
      "SGDRegressor: Train -> 0.38681047717767203, Test -> 0.3780593763181497\n",
      "KNeighborsRegressor: Train -> 0.45601102715331177, Test -> 0.20119569474425458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\usuario\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPRegressor: Train -> 0.6256548648274971, Test -> 0.3354892603150631\n",
      "DecisionTreeRegressor: Train -> 1.0, Test -> -0.2706474065496747\n",
      "RandomForestRegressor: Train -> 0.8983461358435375, Test -> 0.27084878223910713\n"
     ]
    }
   ],
   "source": [
    "model_list = [LinearRegression(),SGDRegressor(),KNeighborsRegressor(), MLPRegressor(),DecisionTreeRegressor(),RandomForestRegressor()]\n",
    "models_automation(model_list, X_train_pca, y_train_D,X_test_pca,y_test_D)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The evaluation of the regression models shows a mixed performance. Models like Linear Regression and SGDRegressor perform decently on both training and test datasets, with similar R-squared values. However, KNeighborsRegressor and MLPRegressor seem to overfit, as their R-squared scores are significantly higher on the training data compared to the test data. DecisionTreeRegressor shows severe overfitting, with a perfect R-squared on the training set but a negative value on the test set. RandomForestRegressor performs well on the training data but also exhibits some overfitting. To address this, the next step involves reevaluating these models without PCA feature selection to potentially improve their performance and generalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearRegression: Train -> 0.5215740786017105, Test -> 0.5874227507776766\n",
      "SGDRegressor: Train -> 0.4171259522753654, Test -> 0.39740580268177284\n",
      "KNeighborsRegressor: Train -> 0.43334979645267524, Test -> 0.2320018160275681\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\usuario\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPRegressor: Train -> 0.6815220793659139, Test -> 0.3972883194888085\n",
      "DecisionTreeRegressor: Train -> 1.0, Test -> -0.1810128362027792\n",
      "RandomForestRegressor: Train -> 0.9254120575823308, Test -> 0.4359296170863617\n"
     ]
    }
   ],
   "source": [
    "models_automation(model_list, X_train_D, y_train_D,X_test_D,y_test_D)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The latest evaluation of the regression models without PCA feature selection shows some changes in performance. LinearRegression and SGDRegressor still demonstrate decent results, with R-squared values around 0.52 to 0.42 for both training and test sets, indicating moderate fit. However, KNeighborsRegressor and MLPRegressor exhibit some overfitting, with noticeable gaps between their train and test R-squared scores. DecisionTreeRegressor continues to display severe overfitting, achieving a perfect R-squared on the training data but a negative value on the test data. RandomForestRegressor, although performing well on the training data, still shows signs of overfitting, albeit less pronounced than before. \n",
    "\n",
    "The performing model in this case is Linear Regression, ad it displayed the highest and most consistent scores for botht he test and train datasets."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
